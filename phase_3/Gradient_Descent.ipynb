{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13118dd6",
   "metadata": {},
   "source": [
    "# Gradient Descent Objectives \n",
    "* Understand the general process of gradient descent with respect to RSS(cost function) \n",
    "* Be able to define parameters, step size and learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5091e2e",
   "metadata": {},
   "source": [
    "### Simple example of Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# read data into a DataFrame\n",
    "data = pd.read_csv('data/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26953b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(5, random_state=1234)\n",
    "X = data['TV']\n",
    "y = data['Sales']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.ylabel('Sales')\n",
    "plt.xlabel('Tv Advertising Dollars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Radio', 'Newspaper'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_formula(x, slope, intercept):\n",
    "    return slope * x + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da34b84",
   "metadata": {},
   "source": [
    "> Now, we need an initial starting point for gradient descent. Let's choose 0.1 as our initial slope and 0 for our intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope1 = 0.1\n",
    "intercept1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 8))\n",
    "plt.scatter(X, y, label = 'Raw Data')\n",
    "axes = plt.axes()\n",
    "axes.set_ylim([0, 30])\n",
    "plt.plot(X, regression_formula(X, slope1, intercept1), color = 'k', label = 'Regression')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b05453",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_formula(X, slope1, intercept1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd445cd4",
   "metadata": {},
   "source": [
    "**Arithmatically, our function looks like this:**\n",
    "\n",
    "    Sales = 0.1(TV $) + 0 \n",
    "    \n",
    "Now, let's calculate the Sum of Squared Error(Cost function) for this line by plugging in the predicted x-value into our formula and getting the predited y-value and substracting it from the actual y-value. \n",
    "\n",
    "![](https://github.com/justmarkham/DAT4/raw/068d887e4be2eedb1b958b345ae097153f762d75/notebooks/08_estimating_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e920b",
   "metadata": {},
   "source": [
    "## Steps to find the optimal slope and intercept of a line of best fit using RSS as our cost function \n",
    "\n",
    "1. Take the derivative of the loss function for each parameter(gradient).\n",
    "2. Pick random values for the parameters. \n",
    "3. Plug the parameter values into the derivatives. \n",
    "4. Calculate the step sizes (slope * learning rate) \n",
    "5. Calculate new parameters (old parameters - step size) \n",
    "6. Repeat steps 3-5 until max number of steps is reached or minimum step size is reached. \n",
    "\n",
    "![](https://i1.wp.com/ucanalytics.com/blogs/wp-content/uploads/2016/03/Picture1-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea96cd",
   "metadata": {},
   "source": [
    "## Derivatives in gradient descent \n",
    "**A derivative tells us how a function is changing at any given point in time. They calculate the rate of change** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23083f8",
   "metadata": {},
   "source": [
    "## Quick Review - Rules for taking Derivatives\n",
    "\n",
    "1. **Power Rule** - $$f(x) = x^r $$\n",
    "\n",
    "Then, the derivative is: \n",
    "$$ f'(x) = r*x^{r-1} $$\n",
    "\n",
    "2. **Constant factor rule** - $$f(x) = 2x^2 $$\n",
    "\n",
    "\n",
    "$$f'(x) = 2*\\frac{\\Delta f}{\\Delta x} x^{2} = 2*2*x^{2-1} = 4x^1 = 4x $$\n",
    "\n",
    "3. **Addition Rule** - To take a derivative of a function that has multiple terms, simply take the derivative of each of the terms individually.  So for the function above, \n",
    "\n",
    "$$ f(x) = 4x^3 - x^2 + 3x $$\n",
    "\n",
    "$$ f'(x) = 12x^2 - 2x + 3  $$  \n",
    "\n",
    "4. **Chain Rule** - allows us to take partial derivatives of a function with respect to the other variables. See [Canvas lesson](https://my.learn.co/courses/123/assignments/6485?module_item_id=15085)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf2f3d",
   "metadata": {},
   "source": [
    "## Let's walk-thru the steps with the Advertising Data \n",
    "![](img/Intro-gradient-descent.jpg)\n",
    "![](img/walk-thru-GD.jpg)\n",
    "![](img/taking_partial_derivatives_GD.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc21bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
