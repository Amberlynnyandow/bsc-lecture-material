{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Useful-Inputs\" data-toc-modified-id=\"Useful-Inputs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Useful Inputs</a></span></li><li><span><a href=\"#Obtaining-Dataset-&amp;-Train-Test-Split\" data-toc-modified-id=\"Obtaining-Dataset-&amp;-Train-Test-Split-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Obtaining Dataset &amp; Train-Test Split</a></span></li><li><span><a href=\"#Creating-a-Neural-Network\" data-toc-modified-id=\"Creating-a-Neural-Network-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Creating a Neural Network</a></span></li><li><span><a href=\"#Training-the-Model\" data-toc-modified-id=\"Training-the-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training the Model</a></span></li><li><span><a href=\"#Evaluating-the-Trained-Model\" data-toc-modified-id=\"Evaluating-the-Trained-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the Trained Model</a></span></li><li><span><a href=\"#Saving-it-for-later\" data-toc-modified-id=\"Saving-it-for-later-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Saving it for later</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this code can be found at <a href='https://keras.io'>keras.io</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Useful Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Obtaining Dataset & Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nothing different from training other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Split the data set into training, validation, and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                    x_scaled, y, \n",
    "                                    test_size=0.2, random_state=2\n",
    ")\n",
    "cut_off = int(len(x_train) * 0.9)\n",
    "\n",
    "x_valid, x_train = x_train[:cut_off] , x_train[cut_off:] \n",
    "y_valid, y_train = y_train[:cut_off], y_train[cut_off:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`Sequential` is referring to the neural networks we've observed. There are other neural network models that will go beyond this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The actual network; we can decide how many layers & nodes for each layer here as well as other hyperparameters like the activation function.\n",
    "\n",
    "For `softmax` the network is configured to output N values, one for each class in the classification task, and the softmax function is used to normalize the outputs, converting them from weighted sum values into probabilities that sum to one. Each value in the output of the softmax function is interpreted as the probability of membership for each class.\n",
    "\n",
    "Sigmoid would be inappropriate for a multi-classification output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=30, activation='relu', input_dim=4))\n",
    "# Use a 2nd hidden layer for more parameters & complexity\n",
    "# model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compile the model to a form that the computer can more easily work with. Compile specifies a [loss](https://keras.io/api/losses/), [metrics](https://keras.io/api/metrics/) and [optimizer](https://keras.io/api/optimizers/) function. \n",
    "\n",
    "**[On optimizers](https://www.kaggle.com/residentmario/keras-optimizers):** Every time a neural network finishes passing a batch through the network and generating prediction results, it must decide how to use the difference between the results it got and the values it knows to be true to adjust the weights on the nodes so that the network steps towards a solution. The algorithm that determines that step is known as the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amberyandow/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                150       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fda36e93b50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fda36e93bb0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the model structure, we do sequences of feedfoward and then backpropagation to adjust the weights and biases (training/fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 1.2004 - accuracy: 0.1667 - val_loss: 1.0371 - val_accuracy: 0.3519\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1970 - accuracy: 0.1667 - val_loss: 1.0345 - val_accuracy: 0.3519\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1921 - accuracy: 0.1667 - val_loss: 1.0313 - val_accuracy: 0.3519\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1860 - accuracy: 0.1667 - val_loss: 1.0274 - val_accuracy: 0.3519\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1787 - accuracy: 0.1667 - val_loss: 1.0230 - val_accuracy: 0.3519\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1704 - accuracy: 0.1667 - val_loss: 1.0182 - val_accuracy: 0.3519\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1614 - accuracy: 0.1667 - val_loss: 1.0130 - val_accuracy: 0.3519\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1516 - accuracy: 0.1667 - val_loss: 1.0075 - val_accuracy: 0.3611\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1412 - accuracy: 0.1667 - val_loss: 1.0017 - val_accuracy: 0.3704\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1304 - accuracy: 0.1667 - val_loss: 0.9957 - val_accuracy: 0.3704\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1191 - accuracy: 0.1667 - val_loss: 0.9896 - val_accuracy: 0.3704\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1075 - accuracy: 0.1667 - val_loss: 0.9833 - val_accuracy: 0.3796\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0956 - accuracy: 0.1667 - val_loss: 0.9768 - val_accuracy: 0.3796\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0834 - accuracy: 0.1667 - val_loss: 0.9703 - val_accuracy: 0.3796\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0712 - accuracy: 0.1667 - val_loss: 0.9638 - val_accuracy: 0.3796\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0588 - accuracy: 0.1667 - val_loss: 0.9572 - val_accuracy: 0.3796\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0463 - accuracy: 0.1667 - val_loss: 0.9506 - val_accuracy: 0.3796\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0339 - accuracy: 0.1667 - val_loss: 0.9440 - val_accuracy: 0.3889\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0215 - accuracy: 0.1667 - val_loss: 0.9375 - val_accuracy: 0.3981\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0092 - accuracy: 0.1667 - val_loss: 0.9310 - val_accuracy: 0.4259\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9970 - accuracy: 0.1667 - val_loss: 0.9246 - val_accuracy: 0.4537\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9849 - accuracy: 0.2500 - val_loss: 0.9182 - val_accuracy: 0.5093\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9730 - accuracy: 0.3333 - val_loss: 0.9119 - val_accuracy: 0.5463\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9612 - accuracy: 0.3333 - val_loss: 0.9057 - val_accuracy: 0.6019\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9496 - accuracy: 0.5000 - val_loss: 0.8996 - val_accuracy: 0.6204\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9381 - accuracy: 0.5833 - val_loss: 0.8935 - val_accuracy: 0.6389\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9269 - accuracy: 0.6667 - val_loss: 0.8876 - val_accuracy: 0.6481\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9159 - accuracy: 0.6667 - val_loss: 0.8818 - val_accuracy: 0.6667\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9050 - accuracy: 0.7500 - val_loss: 0.8761 - val_accuracy: 0.6759\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8944 - accuracy: 0.8333 - val_loss: 0.8705 - val_accuracy: 0.6759\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8840 - accuracy: 0.8333 - val_loss: 0.8649 - val_accuracy: 0.6759\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8738 - accuracy: 0.8333 - val_loss: 0.8595 - val_accuracy: 0.6759\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8638 - accuracy: 0.8333 - val_loss: 0.8543 - val_accuracy: 0.6759\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8541 - accuracy: 0.8333 - val_loss: 0.8491 - val_accuracy: 0.6759\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8446 - accuracy: 0.8333 - val_loss: 0.8440 - val_accuracy: 0.6759\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8353 - accuracy: 0.8333 - val_loss: 0.8390 - val_accuracy: 0.6759\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8262 - accuracy: 0.8333 - val_loss: 0.8341 - val_accuracy: 0.6759\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8173 - accuracy: 0.8333 - val_loss: 0.8293 - val_accuracy: 0.6852\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8086 - accuracy: 0.8333 - val_loss: 0.8246 - val_accuracy: 0.6852\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8002 - accuracy: 0.8333 - val_loss: 0.8200 - val_accuracy: 0.6852\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7919 - accuracy: 0.8333 - val_loss: 0.8155 - val_accuracy: 0.7037\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7837 - accuracy: 0.8333 - val_loss: 0.8111 - val_accuracy: 0.7130\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7757 - accuracy: 0.8333 - val_loss: 0.8068 - val_accuracy: 0.7130\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7680 - accuracy: 0.8333 - val_loss: 0.8025 - val_accuracy: 0.7222\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7603 - accuracy: 0.8333 - val_loss: 0.7984 - val_accuracy: 0.7222\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7529 - accuracy: 0.8333 - val_loss: 0.7943 - val_accuracy: 0.7222\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7457 - accuracy: 0.8333 - val_loss: 0.7903 - val_accuracy: 0.7222\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7386 - accuracy: 0.8333 - val_loss: 0.7864 - val_accuracy: 0.7222\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7318 - accuracy: 0.8333 - val_loss: 0.7826 - val_accuracy: 0.7222\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7250 - accuracy: 0.8333 - val_loss: 0.7788 - val_accuracy: 0.7315\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7185 - accuracy: 0.8333 - val_loss: 0.7751 - val_accuracy: 0.7315\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7120 - accuracy: 0.8333 - val_loss: 0.7716 - val_accuracy: 0.7315\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7058 - accuracy: 0.8333 - val_loss: 0.7680 - val_accuracy: 0.7407\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6997 - accuracy: 0.8333 - val_loss: 0.7646 - val_accuracy: 0.7593\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6937 - accuracy: 0.8333 - val_loss: 0.7612 - val_accuracy: 0.7593\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6879 - accuracy: 0.8333 - val_loss: 0.7579 - val_accuracy: 0.7685\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6822 - accuracy: 0.8333 - val_loss: 0.7547 - val_accuracy: 0.7685\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6766 - accuracy: 0.8333 - val_loss: 0.7515 - val_accuracy: 0.7778\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6712 - accuracy: 0.8333 - val_loss: 0.7483 - val_accuracy: 0.7870\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6659 - accuracy: 0.8333 - val_loss: 0.7453 - val_accuracy: 0.7963\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6607 - accuracy: 0.8333 - val_loss: 0.7423 - val_accuracy: 0.8148\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6557 - accuracy: 0.8333 - val_loss: 0.7393 - val_accuracy: 0.8148\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6507 - accuracy: 0.8333 - val_loss: 0.7364 - val_accuracy: 0.8426\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6459 - accuracy: 0.8333 - val_loss: 0.7336 - val_accuracy: 0.8519\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6412 - accuracy: 0.8333 - val_loss: 0.7308 - val_accuracy: 0.8519\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6366 - accuracy: 0.8333 - val_loss: 0.7280 - val_accuracy: 0.8611\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6320 - accuracy: 0.8333 - val_loss: 0.7253 - val_accuracy: 0.8519\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6276 - accuracy: 0.8333 - val_loss: 0.7227 - val_accuracy: 0.8519\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6233 - accuracy: 0.8333 - val_loss: 0.7201 - val_accuracy: 0.8519\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6190 - accuracy: 0.8333 - val_loss: 0.7176 - val_accuracy: 0.8519\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6149 - accuracy: 0.8333 - val_loss: 0.7151 - val_accuracy: 0.8519\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6108 - accuracy: 0.8333 - val_loss: 0.7126 - val_accuracy: 0.8519\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6069 - accuracy: 0.8333 - val_loss: 0.7102 - val_accuracy: 0.8611\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6029 - accuracy: 0.8333 - val_loss: 0.7078 - val_accuracy: 0.8704\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5991 - accuracy: 0.8333 - val_loss: 0.7054 - val_accuracy: 0.8889\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5954 - accuracy: 0.8333 - val_loss: 0.7031 - val_accuracy: 0.8889\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5917 - accuracy: 0.8333 - val_loss: 0.7009 - val_accuracy: 0.8889\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5881 - accuracy: 0.8333 - val_loss: 0.6986 - val_accuracy: 0.8889\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5845 - accuracy: 0.8333 - val_loss: 0.6964 - val_accuracy: 0.8889\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5811 - accuracy: 0.8333 - val_loss: 0.6943 - val_accuracy: 0.8889\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5777 - accuracy: 0.8333 - val_loss: 0.6921 - val_accuracy: 0.8889\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5743 - accuracy: 0.9167 - val_loss: 0.6900 - val_accuracy: 0.8889\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.6880 - val_accuracy: 0.8889\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5678 - accuracy: 0.9167 - val_loss: 0.6859 - val_accuracy: 0.8981\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5647 - accuracy: 0.9167 - val_loss: 0.6839 - val_accuracy: 0.8981\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5616 - accuracy: 0.9167 - val_loss: 0.6820 - val_accuracy: 0.9074\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5586 - accuracy: 0.9167 - val_loss: 0.6800 - val_accuracy: 0.9074\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5556 - accuracy: 0.9167 - val_loss: 0.6781 - val_accuracy: 0.9074\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5527 - accuracy: 0.9167 - val_loss: 0.6762 - val_accuracy: 0.9074\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5498 - accuracy: 0.9167 - val_loss: 0.6743 - val_accuracy: 0.9167\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5470 - accuracy: 0.9167 - val_loss: 0.6725 - val_accuracy: 0.9167\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5443 - accuracy: 0.9167 - val_loss: 0.6706 - val_accuracy: 0.9167\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5415 - accuracy: 0.9167 - val_loss: 0.6688 - val_accuracy: 0.9167\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5389 - accuracy: 0.9167 - val_loss: 0.6670 - val_accuracy: 0.9167\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5362 - accuracy: 0.9167 - val_loss: 0.6653 - val_accuracy: 0.9259\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5336 - accuracy: 0.9167 - val_loss: 0.6636 - val_accuracy: 0.9259\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5311 - accuracy: 0.9167 - val_loss: 0.6618 - val_accuracy: 0.9259\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5285 - accuracy: 0.9167 - val_loss: 0.6601 - val_accuracy: 0.9259\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5261 - accuracy: 0.9167 - val_loss: 0.6585 - val_accuracy: 0.9352\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5236 - accuracy: 0.9167 - val_loss: 0.6568 - val_accuracy: 0.9352\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5212 - accuracy: 0.9167 - val_loss: 0.6551 - val_accuracy: 0.9352\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5189 - accuracy: 0.9167 - val_loss: 0.6535 - val_accuracy: 0.9352\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5165 - accuracy: 0.9167 - val_loss: 0.6519 - val_accuracy: 0.9352\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5142 - accuracy: 0.9167 - val_loss: 0.6503 - val_accuracy: 0.9352\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5120 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.9352\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5097 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.9352\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5075 - accuracy: 1.0000 - val_loss: 0.6457 - val_accuracy: 0.9352\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5054 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.9444\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5032 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.9352\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5011 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.9352\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4991 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.9352\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4970 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.9352\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4950 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.9352\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4931 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.9352\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4911 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9352\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4892 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.9352\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4873 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.9259\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4854 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.9259\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4836 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.9259\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4818 - accuracy: 1.0000 - val_loss: 0.6269 - val_accuracy: 0.9167\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4800 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.9167\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4782 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.9167\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4764 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.9074\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4747 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.9074\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4730 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.9074\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4713 - accuracy: 1.0000 - val_loss: 0.6189 - val_accuracy: 0.9074\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4696 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.9074\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4680 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.9167\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4663 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9167\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4647 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.9167\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4631 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.9167\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4616 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.9167\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4600 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.9167\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4585 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.9167\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4570 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.9167\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4555 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.9167\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4540 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9167\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4525 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9167\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4510 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.9167\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4496 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.9167\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4481 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.9167\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4467 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.9167\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4453 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.9167\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4440 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.9167\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4426 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.9167\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4412 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.9167\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4399 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9167\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4386 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.9167\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4373 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.9167\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4360 - accuracy: 1.0000 - val_loss: 0.5904 - val_accuracy: 0.9167\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4347 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.9167\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4334 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.9167\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4321 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.9167\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4309 - accuracy: 1.0000 - val_loss: 0.5861 - val_accuracy: 0.9167\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4296 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.9167\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4284 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.9167\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4271 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.9167\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4259 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.9167\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4247 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.9167\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4235 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.9167\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4223 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.9167\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4212 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.9259\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4200 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.9259\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4188 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.9259\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4177 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.9259\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4165 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.9259\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4154 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.9259\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4143 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.9259\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4132 - accuracy: 1.0000 - val_loss: 0.5710 - val_accuracy: 0.9259\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4121 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9259\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4110 - accuracy: 1.0000 - val_loss: 0.5690 - val_accuracy: 0.9259\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4099 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.9259\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4088 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.9259\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4077 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4066 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.9259\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4056 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.9167\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4045 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.9167\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4035 - accuracy: 1.0000 - val_loss: 0.5624 - val_accuracy: 0.9074\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4024 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.9074\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4014 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.9074\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4004 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.9074\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3993 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.9074\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3983 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.9074\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.9074\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3963 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.9074\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3953 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.9074\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3943 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.9074\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3933 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.9074\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3924 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.9074\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3914 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.9074\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3904 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.9074\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3895 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.9074\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3885 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.9074\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3876 - accuracy: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.9167\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3866 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.9074\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3857 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.9074\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3847 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9167\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3838 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.9167\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3829 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.9167\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3820 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.9167\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3811 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9167\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3802 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.9167\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3793 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.9167\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3784 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.9167\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3775 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.8981\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3766 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.8981\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8981\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3748 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.8981\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3739 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8981\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3731 - accuracy: 1.0000 - val_loss: 0.5349 - val_accuracy: 0.8981\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3722 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.8981\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.8981\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3705 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.8981\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3696 - accuracy: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.8981\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3688 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8981\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3679 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8981\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3671 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.8981\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.8981\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3654 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.8981\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3646 - accuracy: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.8981\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3638 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.8981\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3630 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.8981\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3622 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.8981\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3613 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.8981\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3605 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8981\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3597 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8981\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3589 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8981\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3581 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8981\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3573 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.8981\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3566 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.8981\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3558 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.8981\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3550 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3542 - accuracy: 1.0000 - val_loss: 0.5173 - val_accuracy: 0.9074\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3534 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.9074\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3527 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.9074\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3519 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9074\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3511 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.9074\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3503 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9074\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3496 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.9074\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3488 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.9074\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3481 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.9074\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3473 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9074\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3466 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.9074\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3458 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9074\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3451 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9074\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3443 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.9074\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3436 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9074\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3429 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9074\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3421 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9074\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3414 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9074\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3407 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9074\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3400 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.9074\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3392 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9074\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3385 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8981\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3378 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.8981\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3371 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.8981\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3364 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8981\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3357 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8981\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3350 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8981\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3343 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8981\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3336 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8981\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3329 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8981\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3322 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8981\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3315 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.8981\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3308 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8981\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.8981\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3295 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8981\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3288 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8981\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3281 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8981\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3275 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8981\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3268 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.8981\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.8981\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3255 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8981\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3248 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8981\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3241 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.8981\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3235 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.8981\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3228 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8981\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3222 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8889\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3215 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.8889\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3209 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.8889\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3202 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.8889\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3196 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.8796\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3190 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.8796\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3183 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.8796\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3177 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.8796\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8796\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3165 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8796\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3158 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.8796\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3152 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8796\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.8796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3140 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.8796\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3133 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8796\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3127 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.8796\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3121 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8796\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.8796\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3109 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.8796\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3103 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.8796\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3097 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8796\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3091 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.8796\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3085 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.8796\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3079 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8704\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3073 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8704\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3067 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.8704\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3061 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.8704\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3055 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.8704\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3049 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.8704\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3043 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.8704\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3037 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8704\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3032 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.8704\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3026 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8704\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3020 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8704\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3014 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.8704\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3008 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.8704\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3003 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8704\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2997 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.8704\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2991 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.8704\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2986 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.8704\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2980 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.8704\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8704\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2969 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8704\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2963 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.8704\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2957 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.8704\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2952 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.8704\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8704\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2941 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.8704\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2935 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.8704\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2930 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.8704\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2924 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.8704\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2919 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.8704\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2913 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.8704\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2908 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.8704\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2903 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.8704\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.8704\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2892 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.8704\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2886 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.8704\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8704\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2876 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.8704\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2870 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8704\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.8704\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2860 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.8704\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.8704\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8704\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.8704\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8704\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2833 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8704\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8704\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.8704\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2818 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2813 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.8704\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2807 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.8704\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2802 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.8704\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2797 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8704\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2792 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.8704\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2787 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.8704\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2782 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8704\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2777 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8704\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2772 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.8704\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2766 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8704\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2761 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.8704\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8704\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2751 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8704\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2746 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.8704\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2741 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8704\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8704\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.8704\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2726 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.8704\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2722 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.8704\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2717 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8704\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2712 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8704\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2707 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8704\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2702 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.8704\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2697 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8704\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2692 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8704\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8704\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2683 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8704\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2678 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8704\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2673 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8704\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2668 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.8704\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2663 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8704\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2659 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.8704\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2654 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8704\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2649 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8704\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2644 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8704\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2640 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8704\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2635 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8704\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.8704\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2626 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8704\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8704\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8704\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2612 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.8704\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2607 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.8704\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2602 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8704\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2598 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8704\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2593 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.8704\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2588 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8704\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2584 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8704\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8704\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2575 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8704\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2570 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.8704\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2566 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8704\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2561 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8704\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2556 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.8704\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2552 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8704\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8704\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8704\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2538 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2534 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8704\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2529 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.8704\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2525 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.8704\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2521 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.8704\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2516 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.8704\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2512 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.8704\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8704\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2503 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8704\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2498 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8704\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2494 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.8704\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2490 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.8704\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2485 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8704\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2481 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.8704\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8704\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2472 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8704\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2468 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8704\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2463 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.8704\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2459 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8704\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2455 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8704\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2451 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8704\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2446 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.8704\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2442 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.8704\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2438 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.8704\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2433 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8704\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8704\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.8704\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.8611\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.8611\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8611\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8611\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.8611\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2400 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.8611\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2395 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8611\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.8611\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8611\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2383 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8611\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2379 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.8611\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2375 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8611\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.8611\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2366 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8611\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2362 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8611\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8611\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2354 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.8611\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2350 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8611\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2346 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8611\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2342 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.8611\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2338 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.8611\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2334 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.8611\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.8611\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.8611\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8611\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2317 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8611\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2313 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.8611\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2309 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.8611\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2305 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.8611\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2301 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.8611\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.8611\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2293 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.8611\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2286 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8611\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.8611\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2278 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.8611\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2274 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8611\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2270 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8611\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8611\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2262 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.8611\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2258 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.8611\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.8611\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8611\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2246 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.8611\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.8611\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.8611\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.8611\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.8611\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2227 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8611\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2223 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.8611\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2219 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.8611\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.8611\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.8611\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.8611\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.8611\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8611\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.8611\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.8611\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8611\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2184 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.8611\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.8611\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.8611\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.8611\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.8611\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.8611\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.8611\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.8611\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=500, #batch_size=256,\n",
    "                    validation_data = (x_valid, y_valid)\n",
    "                    # validation_split=0.2 # Optionally use a split here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# alternatively could have specified a specific batch to train on\n",
    "# model.train_on_batch(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [[ 0.13833044 -0.30618307  0.21161954 -0.40232584  0.40874112  0.32601342\n",
      "   0.30998743 -0.10565681  0.41765895 -0.09087156 -0.17173725  0.29450163\n",
      "  -0.10429982 -0.5193182   0.11033151  0.34195065  0.34655607 -0.0013097\n",
      "  -0.31897944  0.4021772  -0.11851886  0.39577153  0.08406683 -0.38306358\n",
      "  -0.29634687 -0.4829245   0.156313    0.17784747 -0.26908016 -0.19666837]\n",
      " [-0.283151   -0.24732831  0.0202339   0.06249931  0.03863263 -0.31455502\n",
      "   0.30182734 -0.43738598 -0.12106036 -0.17180431  0.11847759  0.09433369\n",
      "  -0.0704611   0.16647418  0.31727564 -0.03035708 -0.16040796  0.2356114\n",
      "  -0.05751481  0.11625437  0.1723105  -0.00941323  0.03681389  0.45496142\n",
      "   0.10942931  0.50264496 -0.17378786  0.00193018 -0.08806556  0.08306248]\n",
      " [ 0.18700142  0.47915012  0.39443976 -0.47336102  0.21570009  0.49536654\n",
      "  -0.01879044  0.11547083 -0.3810345   0.03502479  0.07241547 -0.35857585\n",
      "  -0.40204936  0.01909809  0.22349674 -0.14519577 -0.27468166 -0.21874759\n",
      "   0.10312782  0.2853448   0.45228484  0.3304806  -0.29957816 -0.4774913\n",
      "   0.02865111  0.12430469 -0.04641127  0.07074862  0.4409225  -0.20263284]\n",
      " [ 0.3379908   0.3231598   0.15994133 -0.39664775 -0.02741103  0.3431081\n",
      "  -0.49650574 -0.17438602  0.3664979   0.50228196 -0.25697455 -0.3323724\n",
      "  -0.28093472 -0.50708467  0.45846686  0.2577519   0.26056552  0.20886295\n",
      "  -0.18847993  0.01945323  0.31243005  0.329275    0.4423857  -0.20780474\n",
      "  -0.13468578  0.05408077  0.37825182 -0.26493436 -0.03563951  0.35648695]]\n",
      "\n",
      "Biases:\n",
      " [ 0.20398104  0.11227463 -0.08246128  0.05762625 -0.01723008  0.19197793\n",
      "  0.16545461  0.26335528  0.04200206 -0.08477637 -0.02694828 -0.0128329\n",
      " -0.00600912  0.08229562 -0.02041272  0.0918109   0.02748903 -0.09094568\n",
      " -0.04424051  0.04004928  0.17272975 -0.01969521  0.02720642  0.06295476\n",
      "  0.07935631  0.08349989 -0.04086032  0.14155382  0.11879693 -0.13533455]\n"
     ]
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print('Weights:\\n', weights)\n",
    "print()\n",
    "print('Biases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluating the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "columns = ['accuracy', 'val_accuracy']\n",
    "\n",
    "df[columns].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "columns = ['loss', 'val_loss']\n",
    "\n",
    "df[columns].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can look at the overall loss from our test data after training the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3082 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30815601348876953, 0.8666666746139526]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Could also just use a batch to evaluate\n",
    "# loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test)\n",
    "\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can have predictions (probability the data point is a particular class based on our trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9831541 , 0.0112363 , 0.00560954],\n",
       "       [0.9714325 , 0.02034736, 0.00822023],\n",
       "       [0.01643817, 0.5986302 , 0.38493162],\n",
       "       [0.9620322 , 0.02816206, 0.00980577],\n",
       "       [0.9775195 , 0.01549055, 0.00698985],\n",
       "       [0.02194154, 0.5325816 , 0.44547683],\n",
       "       [0.9400936 , 0.04472617, 0.01518022],\n",
       "       [0.008625  , 0.5931227 , 0.39825237],\n",
       "       [0.01024769, 0.40202597, 0.58772635],\n",
       "       [0.95049256, 0.03584979, 0.01365758],\n",
       "       [0.980515  , 0.01380033, 0.0056847 ],\n",
       "       [0.98322165, 0.0115147 , 0.00526359],\n",
       "       [0.96721464, 0.02318187, 0.00960355],\n",
       "       [0.9779433 , 0.01591822, 0.00613848],\n",
       "       [0.1607954 , 0.47261852, 0.36658615],\n",
       "       [0.05099057, 0.63696986, 0.31203952],\n",
       "       [0.8672658 , 0.11075184, 0.02198234],\n",
       "       [0.12831622, 0.65242237, 0.21926138],\n",
       "       [0.00690052, 0.19802551, 0.7950739 ],\n",
       "       [0.0858281 , 0.7201202 , 0.1940517 ],\n",
       "       [0.03670324, 0.5027009 , 0.46059582],\n",
       "       [0.09890826, 0.6686097 , 0.2324821 ],\n",
       "       [0.01444483, 0.270796  , 0.7147592 ],\n",
       "       [0.0974598 , 0.69323385, 0.20930628],\n",
       "       [0.03850507, 0.78128034, 0.1802146 ],\n",
       "       [0.97297305, 0.01901983, 0.0080071 ],\n",
       "       [0.97622097, 0.01655282, 0.00722633],\n",
       "       [0.04037625, 0.48252997, 0.47709376],\n",
       "       [0.9800663 , 0.01394771, 0.005986  ],\n",
       "       [0.01753151, 0.39879104, 0.5836774 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = model.predict(x_test)\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We want to say what is the predicted class, so we pick just the largest probability for each result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1,\n",
       "       2, 1, 1, 0, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(classes, axis=1)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, we can see how accurate our model was by seeing if the predicted classes match the actual labels. Note that this is calculated differently from how the loss is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86666667])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions  == np.argmax(y_test, axis=1)) / predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Saving it for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review \n",
    "- function of a perceptron from inputs to outputs = `output = activation(dot(inputs, weights) + bias)`\n",
    "- Forward Propagation - transformations from each node propagate to the next layers nodes. \n",
    "- Back-propagation - Updating weights and bias based on residuals \n",
    "- What is an activation function? \n",
    "- What is an optimizer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
