{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Useful-Inputs\" data-toc-modified-id=\"Useful-Inputs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Useful Inputs</a></span></li><li><span><a href=\"#Obtaining-Dataset-&amp;-Train-Test-Split\" data-toc-modified-id=\"Obtaining-Dataset-&amp;-Train-Test-Split-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Obtaining Dataset &amp; Train-Test Split</a></span></li><li><span><a href=\"#Creating-a-Neural-Network\" data-toc-modified-id=\"Creating-a-Neural-Network-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Creating a Neural Network</a></span></li><li><span><a href=\"#Training-the-Model\" data-toc-modified-id=\"Training-the-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training the Model</a></span></li><li><span><a href=\"#Evaluating-the-Trained-Model\" data-toc-modified-id=\"Evaluating-the-Trained-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the Trained Model</a></span></li><li><span><a href=\"#Saving-it-for-later\" data-toc-modified-id=\"Saving-it-for-later-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Saving it for later</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this code can be found at <a href='https://keras.io'>keras.io</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Useful Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Obtaining Dataset & Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nothing different from training other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Split the data set into training, validation, and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                    x_scaled, y, \n",
    "                                    test_size=0.2, random_state=2\n",
    ")\n",
    "cut_off = int(len(x_train) * 0.9)\n",
    "\n",
    "x_valid, x_train = x_train[:cut_off] , x_train[cut_off:] \n",
    "y_valid, y_train = y_train[:cut_off], y_train[cut_off:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`Sequential` is referring to the neural networks we've observed. There are other neural network models that will go beyond this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The actual network; we can decide how many layers & nodes for each layer here as well as other hyperparameters like the activation function.\n",
    "\n",
    "For `softmax` the network is configured to output N values, one for each class in the classification task, and the softmax function is used to normalize the outputs, converting them from weighted sum values into probabilities that sum to one. Each value in the output of the softmax function is interpreted as the probability of membership for each class.\n",
    "\n",
    "Sigmoid would be inappropriate for a multi-classification output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=30, activation='relu', input_dim=4))\n",
    "# Use a 2nd hidden layer for more parameters & complexity\n",
    "# model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compile the model to a form that the computer can more easily work with. Compile specifies a [loss](https://keras.io/api/losses/), [metrics](https://keras.io/api/metrics/) and [optimizer](https://keras.io/api/optimizers/) function. \n",
    "\n",
    "**[On optimizers](https://www.kaggle.com/residentmario/keras-optimizers):** Every time a neural network finishes passing a batch through the network and generating prediction results, it must decide how to use the difference between the results it got and the values it knows to be true to adjust the weights on the nodes so that the network steps towards a solution. The algorithm that determines that step is known as the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amberyandow/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "module_wrapper (ModuleWrappe (None, 30)                150       \n",
      "_________________________________________________________________\n",
      "module_wrapper_1 (ModuleWrap (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.functional.ModuleWrapper at 0x7fea80006a00>,\n",
       " <tensorflow.python.keras.engine.functional.ModuleWrapper at 0x7fea80006e80>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the model structure, we do sequences of feedfoward and then backpropagation to adjust the weights and biases (training/fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.4922 - accuracy: 0.0000e+00 - val_loss: 1.4545 - val_accuracy: 0.0556\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4876 - accuracy: 0.0000e+00 - val_loss: 1.4507 - val_accuracy: 0.0556\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4812 - accuracy: 0.0000e+00 - val_loss: 1.4460 - val_accuracy: 0.0556\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4732 - accuracy: 0.0000e+00 - val_loss: 1.4404 - val_accuracy: 0.0556\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4637 - accuracy: 0.0000e+00 - val_loss: 1.4341 - val_accuracy: 0.0556\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4530 - accuracy: 0.0000e+00 - val_loss: 1.4271 - val_accuracy: 0.0556\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4412 - accuracy: 0.0000e+00 - val_loss: 1.4196 - val_accuracy: 0.0556\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4286 - accuracy: 0.0000e+00 - val_loss: 1.4117 - val_accuracy: 0.0556\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4152 - accuracy: 0.0000e+00 - val_loss: 1.4033 - val_accuracy: 0.0556\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4012 - accuracy: 0.0000e+00 - val_loss: 1.3946 - val_accuracy: 0.0556\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3866 - accuracy: 0.0000e+00 - val_loss: 1.3856 - val_accuracy: 0.0556\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3716 - accuracy: 0.0000e+00 - val_loss: 1.3764 - val_accuracy: 0.0556\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3563 - accuracy: 0.0000e+00 - val_loss: 1.3671 - val_accuracy: 0.0556\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3408 - accuracy: 0.0000e+00 - val_loss: 1.3577 - val_accuracy: 0.0556\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3252 - accuracy: 0.0000e+00 - val_loss: 1.3482 - val_accuracy: 0.0648\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3095 - accuracy: 0.0000e+00 - val_loss: 1.3387 - val_accuracy: 0.0648\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2938 - accuracy: 0.0000e+00 - val_loss: 1.3292 - val_accuracy: 0.0648\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2781 - accuracy: 0.0000e+00 - val_loss: 1.3198 - val_accuracy: 0.0648\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2625 - accuracy: 0.0000e+00 - val_loss: 1.3103 - val_accuracy: 0.0741\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2471 - accuracy: 0.0000e+00 - val_loss: 1.3010 - val_accuracy: 0.0741\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2317 - accuracy: 0.0000e+00 - val_loss: 1.2917 - val_accuracy: 0.0741\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2166 - accuracy: 0.0000e+00 - val_loss: 1.2825 - val_accuracy: 0.0741\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2018 - accuracy: 0.0000e+00 - val_loss: 1.2734 - val_accuracy: 0.0741\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1871 - accuracy: 0.0000e+00 - val_loss: 1.2645 - val_accuracy: 0.0741\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1728 - accuracy: 0.0000e+00 - val_loss: 1.2557 - val_accuracy: 0.0741\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1586 - accuracy: 0.0000e+00 - val_loss: 1.2470 - val_accuracy: 0.0833\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1448 - accuracy: 0.0000e+00 - val_loss: 1.2384 - val_accuracy: 0.1481\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1312 - accuracy: 0.0000e+00 - val_loss: 1.2301 - val_accuracy: 0.1574\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1179 - accuracy: 0.0833 - val_loss: 1.2219 - val_accuracy: 0.1759\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1048 - accuracy: 0.2500 - val_loss: 1.2138 - val_accuracy: 0.1852\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0920 - accuracy: 0.2500 - val_loss: 1.2060 - val_accuracy: 0.2222\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0796 - accuracy: 0.4167 - val_loss: 1.1982 - val_accuracy: 0.2407\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0674 - accuracy: 0.4167 - val_loss: 1.1906 - val_accuracy: 0.2870\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0556 - accuracy: 0.4167 - val_loss: 1.1831 - val_accuracy: 0.2963\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0441 - accuracy: 0.4167 - val_loss: 1.1758 - val_accuracy: 0.3241\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0328 - accuracy: 0.5000 - val_loss: 1.1686 - val_accuracy: 0.3333\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0218 - accuracy: 0.5000 - val_loss: 1.1616 - val_accuracy: 0.3333\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0110 - accuracy: 0.5000 - val_loss: 1.1547 - val_accuracy: 0.3426\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0006 - accuracy: 0.5000 - val_loss: 1.1480 - val_accuracy: 0.3611\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9904 - accuracy: 0.5000 - val_loss: 1.1414 - val_accuracy: 0.3519\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9804 - accuracy: 0.5000 - val_loss: 1.1349 - val_accuracy: 0.3611\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9706 - accuracy: 0.5833 - val_loss: 1.1286 - val_accuracy: 0.3611\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9611 - accuracy: 0.5833 - val_loss: 1.1225 - val_accuracy: 0.3611\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9519 - accuracy: 0.5833 - val_loss: 1.1164 - val_accuracy: 0.3704\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9428 - accuracy: 0.5833 - val_loss: 1.1105 - val_accuracy: 0.3704\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9339 - accuracy: 0.5833 - val_loss: 1.1047 - val_accuracy: 0.3889\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9253 - accuracy: 0.5833 - val_loss: 1.0991 - val_accuracy: 0.3889\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9169 - accuracy: 0.5833 - val_loss: 1.0935 - val_accuracy: 0.3889\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9087 - accuracy: 0.5833 - val_loss: 1.0881 - val_accuracy: 0.3981\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9007 - accuracy: 0.5833 - val_loss: 1.0828 - val_accuracy: 0.3981\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8928 - accuracy: 0.5833 - val_loss: 1.0776 - val_accuracy: 0.3981\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8851 - accuracy: 0.5833 - val_loss: 1.0725 - val_accuracy: 0.3981\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8776 - accuracy: 0.5833 - val_loss: 1.0675 - val_accuracy: 0.3981\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8700 - accuracy: 0.5833 - val_loss: 1.0626 - val_accuracy: 0.3981\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8624 - accuracy: 0.5833 - val_loss: 1.0577 - val_accuracy: 0.3981\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8549 - accuracy: 0.5833 - val_loss: 1.0530 - val_accuracy: 0.3981\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8475 - accuracy: 0.5833 - val_loss: 1.0483 - val_accuracy: 0.3981\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8404 - accuracy: 0.5833 - val_loss: 1.0437 - val_accuracy: 0.3981\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8333 - accuracy: 0.5833 - val_loss: 1.0392 - val_accuracy: 0.3981\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8264 - accuracy: 0.5833 - val_loss: 1.0347 - val_accuracy: 0.4074\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8197 - accuracy: 0.5833 - val_loss: 1.0304 - val_accuracy: 0.4074\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8131 - accuracy: 0.5833 - val_loss: 1.0261 - val_accuracy: 0.4074\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8067 - accuracy: 0.5833 - val_loss: 1.0220 - val_accuracy: 0.4167\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8004 - accuracy: 0.5833 - val_loss: 1.0179 - val_accuracy: 0.4167\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7942 - accuracy: 0.5833 - val_loss: 1.0138 - val_accuracy: 0.4167\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7881 - accuracy: 0.5833 - val_loss: 1.0099 - val_accuracy: 0.4259\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7822 - accuracy: 0.5833 - val_loss: 1.0060 - val_accuracy: 0.4259\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7764 - accuracy: 0.5833 - val_loss: 1.0021 - val_accuracy: 0.4259\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7707 - accuracy: 0.5833 - val_loss: 0.9984 - val_accuracy: 0.4259\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7651 - accuracy: 0.5833 - val_loss: 0.9946 - val_accuracy: 0.4259\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7597 - accuracy: 0.5833 - val_loss: 0.9909 - val_accuracy: 0.4259\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7543 - accuracy: 0.5833 - val_loss: 0.9873 - val_accuracy: 0.4259\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7491 - accuracy: 0.5833 - val_loss: 0.9838 - val_accuracy: 0.4259\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7439 - accuracy: 0.5833 - val_loss: 0.9803 - val_accuracy: 0.4259\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7389 - accuracy: 0.5833 - val_loss: 0.9769 - val_accuracy: 0.4259\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7340 - accuracy: 0.5833 - val_loss: 0.9735 - val_accuracy: 0.4352\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7292 - accuracy: 0.5833 - val_loss: 0.9701 - val_accuracy: 0.4352\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7244 - accuracy: 0.5833 - val_loss: 0.9668 - val_accuracy: 0.4352\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7198 - accuracy: 0.5833 - val_loss: 0.9636 - val_accuracy: 0.4352\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7152 - accuracy: 0.5833 - val_loss: 0.9604 - val_accuracy: 0.4444\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7108 - accuracy: 0.5833 - val_loss: 0.9572 - val_accuracy: 0.4444\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7065 - accuracy: 0.5833 - val_loss: 0.9541 - val_accuracy: 0.4537\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7022 - accuracy: 0.5833 - val_loss: 0.9511 - val_accuracy: 0.4537\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6980 - accuracy: 0.5833 - val_loss: 0.9481 - val_accuracy: 0.4537\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6939 - accuracy: 0.5833 - val_loss: 0.9451 - val_accuracy: 0.4722\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6899 - accuracy: 0.5833 - val_loss: 0.9422 - val_accuracy: 0.4815\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6859 - accuracy: 0.5833 - val_loss: 0.9393 - val_accuracy: 0.4815\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6821 - accuracy: 0.6667 - val_loss: 0.9365 - val_accuracy: 0.4815\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6783 - accuracy: 0.6667 - val_loss: 0.9337 - val_accuracy: 0.4815\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6745 - accuracy: 0.6667 - val_loss: 0.9309 - val_accuracy: 0.4815\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6709 - accuracy: 0.6667 - val_loss: 0.9282 - val_accuracy: 0.4815\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6673 - accuracy: 0.6667 - val_loss: 0.9255 - val_accuracy: 0.4815\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6637 - accuracy: 0.6667 - val_loss: 0.9228 - val_accuracy: 0.4907\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6603 - accuracy: 0.6667 - val_loss: 0.9202 - val_accuracy: 0.5000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6569 - accuracy: 0.6667 - val_loss: 0.9176 - val_accuracy: 0.5000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6535 - accuracy: 0.6667 - val_loss: 0.9151 - val_accuracy: 0.5000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6502 - accuracy: 0.6667 - val_loss: 0.9125 - val_accuracy: 0.5093\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6470 - accuracy: 0.6667 - val_loss: 0.9100 - val_accuracy: 0.5093\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6438 - accuracy: 0.7500 - val_loss: 0.9075 - val_accuracy: 0.5093\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6407 - accuracy: 0.7500 - val_loss: 0.9051 - val_accuracy: 0.5093\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6377 - accuracy: 0.7500 - val_loss: 0.9027 - val_accuracy: 0.5093\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6347 - accuracy: 0.7500 - val_loss: 0.9003 - val_accuracy: 0.5093\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6317 - accuracy: 0.7500 - val_loss: 0.8980 - val_accuracy: 0.5093\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6288 - accuracy: 0.7500 - val_loss: 0.8957 - val_accuracy: 0.5278\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6260 - accuracy: 0.7500 - val_loss: 0.8934 - val_accuracy: 0.5278\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6232 - accuracy: 0.7500 - val_loss: 0.8911 - val_accuracy: 0.5278\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6204 - accuracy: 0.7500 - val_loss: 0.8889 - val_accuracy: 0.5278\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6177 - accuracy: 0.7500 - val_loss: 0.8866 - val_accuracy: 0.5278\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6150 - accuracy: 0.8333 - val_loss: 0.8844 - val_accuracy: 0.5278\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6124 - accuracy: 0.8333 - val_loss: 0.8823 - val_accuracy: 0.5278\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6098 - accuracy: 0.8333 - val_loss: 0.8801 - val_accuracy: 0.5278\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6072 - accuracy: 0.8333 - val_loss: 0.8780 - val_accuracy: 0.5278\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6047 - accuracy: 0.8333 - val_loss: 0.8759 - val_accuracy: 0.5278\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6022 - accuracy: 0.8333 - val_loss: 0.8738 - val_accuracy: 0.5278\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5997 - accuracy: 0.8333 - val_loss: 0.8717 - val_accuracy: 0.5370\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5973 - accuracy: 0.8333 - val_loss: 0.8697 - val_accuracy: 0.5463\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5950 - accuracy: 0.8333 - val_loss: 0.8677 - val_accuracy: 0.5556\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5926 - accuracy: 0.8333 - val_loss: 0.8657 - val_accuracy: 0.5556\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5903 - accuracy: 0.8333 - val_loss: 0.8637 - val_accuracy: 0.5556\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5881 - accuracy: 0.8333 - val_loss: 0.8617 - val_accuracy: 0.5556\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5858 - accuracy: 0.8333 - val_loss: 0.8598 - val_accuracy: 0.5463\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5836 - accuracy: 0.8333 - val_loss: 0.8578 - val_accuracy: 0.5463\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5815 - accuracy: 0.8333 - val_loss: 0.8559 - val_accuracy: 0.5463\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5793 - accuracy: 0.8333 - val_loss: 0.8540 - val_accuracy: 0.5463\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5772 - accuracy: 0.8333 - val_loss: 0.8521 - val_accuracy: 0.5463\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5751 - accuracy: 0.8333 - val_loss: 0.8502 - val_accuracy: 0.5463\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5730 - accuracy: 0.8333 - val_loss: 0.8484 - val_accuracy: 0.5463\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5710 - accuracy: 0.8333 - val_loss: 0.8465 - val_accuracy: 0.5463\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5689 - accuracy: 0.8333 - val_loss: 0.8447 - val_accuracy: 0.5463\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5669 - accuracy: 0.8333 - val_loss: 0.8429 - val_accuracy: 0.5463\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5650 - accuracy: 0.8333 - val_loss: 0.8411 - val_accuracy: 0.5463\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5630 - accuracy: 0.8333 - val_loss: 0.8393 - val_accuracy: 0.5463\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5611 - accuracy: 0.8333 - val_loss: 0.8376 - val_accuracy: 0.5556\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5592 - accuracy: 0.8333 - val_loss: 0.8358 - val_accuracy: 0.5556\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5573 - accuracy: 0.8333 - val_loss: 0.8341 - val_accuracy: 0.5556\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5554 - accuracy: 0.8333 - val_loss: 0.8324 - val_accuracy: 0.5648\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5536 - accuracy: 0.8333 - val_loss: 0.8307 - val_accuracy: 0.5648\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5518 - accuracy: 0.8333 - val_loss: 0.8290 - val_accuracy: 0.5648\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5500 - accuracy: 0.8333 - val_loss: 0.8273 - val_accuracy: 0.5648\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5482 - accuracy: 0.8333 - val_loss: 0.8257 - val_accuracy: 0.5648\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5465 - accuracy: 0.8333 - val_loss: 0.8240 - val_accuracy: 0.5648\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5447 - accuracy: 0.8333 - val_loss: 0.8224 - val_accuracy: 0.5648\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5430 - accuracy: 0.8333 - val_loss: 0.8207 - val_accuracy: 0.5648\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5413 - accuracy: 0.8333 - val_loss: 0.8191 - val_accuracy: 0.5648\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5396 - accuracy: 0.8333 - val_loss: 0.8175 - val_accuracy: 0.5648\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5380 - accuracy: 0.8333 - val_loss: 0.8159 - val_accuracy: 0.5648\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5363 - accuracy: 0.8333 - val_loss: 0.8143 - val_accuracy: 0.5648\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5346 - accuracy: 0.8333 - val_loss: 0.8127 - val_accuracy: 0.5648\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5330 - accuracy: 0.8333 - val_loss: 0.8111 - val_accuracy: 0.5741\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.8333 - val_loss: 0.8096 - val_accuracy: 0.5741\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5298 - accuracy: 0.8333 - val_loss: 0.8080 - val_accuracy: 0.5741\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5282 - accuracy: 0.8333 - val_loss: 0.8065 - val_accuracy: 0.5741\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5266 - accuracy: 0.8333 - val_loss: 0.8049 - val_accuracy: 0.5741\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5251 - accuracy: 0.8333 - val_loss: 0.8034 - val_accuracy: 0.5741\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5235 - accuracy: 0.8333 - val_loss: 0.8018 - val_accuracy: 0.5741\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5220 - accuracy: 0.8333 - val_loss: 0.8003 - val_accuracy: 0.5741\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5205 - accuracy: 0.8333 - val_loss: 0.7987 - val_accuracy: 0.5741\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5190 - accuracy: 0.8333 - val_loss: 0.7972 - val_accuracy: 0.5741\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5175 - accuracy: 0.8333 - val_loss: 0.7957 - val_accuracy: 0.5833\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5160 - accuracy: 0.8333 - val_loss: 0.7942 - val_accuracy: 0.5833\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5145 - accuracy: 0.8333 - val_loss: 0.7927 - val_accuracy: 0.5833\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5131 - accuracy: 0.8333 - val_loss: 0.7913 - val_accuracy: 0.5926\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5117 - accuracy: 0.8333 - val_loss: 0.7898 - val_accuracy: 0.5926\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5102 - accuracy: 0.8333 - val_loss: 0.7883 - val_accuracy: 0.5926\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5088 - accuracy: 0.8333 - val_loss: 0.7869 - val_accuracy: 0.5926\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5075 - accuracy: 0.8333 - val_loss: 0.7855 - val_accuracy: 0.5926\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5061 - accuracy: 0.8333 - val_loss: 0.7840 - val_accuracy: 0.5926\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5047 - accuracy: 0.8333 - val_loss: 0.7826 - val_accuracy: 0.5926\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5034 - accuracy: 0.8333 - val_loss: 0.7812 - val_accuracy: 0.5926\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5020 - accuracy: 0.8333 - val_loss: 0.7798 - val_accuracy: 0.5926\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5007 - accuracy: 0.8333 - val_loss: 0.7784 - val_accuracy: 0.5926\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4994 - accuracy: 0.8333 - val_loss: 0.7770 - val_accuracy: 0.5926\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4981 - accuracy: 0.8333 - val_loss: 0.7756 - val_accuracy: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4968 - accuracy: 0.8333 - val_loss: 0.7743 - val_accuracy: 0.5926\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4955 - accuracy: 0.8333 - val_loss: 0.7729 - val_accuracy: 0.6019\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4942 - accuracy: 0.8333 - val_loss: 0.7715 - val_accuracy: 0.6019\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.8333 - val_loss: 0.7702 - val_accuracy: 0.6019\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4917 - accuracy: 0.8333 - val_loss: 0.7688 - val_accuracy: 0.6019\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4904 - accuracy: 0.8333 - val_loss: 0.7675 - val_accuracy: 0.5926\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4892 - accuracy: 0.8333 - val_loss: 0.7662 - val_accuracy: 0.5926\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4879 - accuracy: 0.8333 - val_loss: 0.7649 - val_accuracy: 0.5926\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4867 - accuracy: 0.8333 - val_loss: 0.7636 - val_accuracy: 0.5926\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4855 - accuracy: 0.8333 - val_loss: 0.7622 - val_accuracy: 0.5926\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4843 - accuracy: 0.8333 - val_loss: 0.7610 - val_accuracy: 0.5926\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4831 - accuracy: 0.8333 - val_loss: 0.7597 - val_accuracy: 0.6019\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4819 - accuracy: 0.8333 - val_loss: 0.7584 - val_accuracy: 0.6019\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4807 - accuracy: 0.8333 - val_loss: 0.7571 - val_accuracy: 0.6019\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4795 - accuracy: 0.8333 - val_loss: 0.7558 - val_accuracy: 0.6019\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4783 - accuracy: 0.8333 - val_loss: 0.7546 - val_accuracy: 0.6019\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4772 - accuracy: 0.8333 - val_loss: 0.7533 - val_accuracy: 0.6111\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4760 - accuracy: 0.8333 - val_loss: 0.7520 - val_accuracy: 0.6111\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4749 - accuracy: 0.8333 - val_loss: 0.7508 - val_accuracy: 0.6111\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4737 - accuracy: 0.8333 - val_loss: 0.7496 - val_accuracy: 0.6111\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4726 - accuracy: 0.8333 - val_loss: 0.7483 - val_accuracy: 0.6111\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4715 - accuracy: 0.8333 - val_loss: 0.7471 - val_accuracy: 0.6111\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4704 - accuracy: 0.8333 - val_loss: 0.7459 - val_accuracy: 0.5926\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4692 - accuracy: 0.8333 - val_loss: 0.7446 - val_accuracy: 0.5926\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4681 - accuracy: 0.8333 - val_loss: 0.7434 - val_accuracy: 0.5926\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4671 - accuracy: 0.8333 - val_loss: 0.7422 - val_accuracy: 0.5926\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4660 - accuracy: 0.8333 - val_loss: 0.7410 - val_accuracy: 0.5926\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4649 - accuracy: 0.8333 - val_loss: 0.7398 - val_accuracy: 0.5926\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4638 - accuracy: 0.8333 - val_loss: 0.7386 - val_accuracy: 0.5926\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4628 - accuracy: 0.8333 - val_loss: 0.7375 - val_accuracy: 0.5926\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4617 - accuracy: 0.8333 - val_loss: 0.7363 - val_accuracy: 0.5926\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4607 - accuracy: 0.8333 - val_loss: 0.7351 - val_accuracy: 0.5926\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4596 - accuracy: 0.8333 - val_loss: 0.7339 - val_accuracy: 0.5926\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4586 - accuracy: 0.8333 - val_loss: 0.7328 - val_accuracy: 0.5926\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4575 - accuracy: 0.8333 - val_loss: 0.7316 - val_accuracy: 0.6019\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4565 - accuracy: 0.8333 - val_loss: 0.7304 - val_accuracy: 0.6019\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4555 - accuracy: 0.8333 - val_loss: 0.7293 - val_accuracy: 0.6019\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.8333 - val_loss: 0.7281 - val_accuracy: 0.6019\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4535 - accuracy: 0.8333 - val_loss: 0.7270 - val_accuracy: 0.6019\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4525 - accuracy: 0.8333 - val_loss: 0.7259 - val_accuracy: 0.6019\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.7247 - val_accuracy: 0.6019\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4505 - accuracy: 0.8333 - val_loss: 0.7236 - val_accuracy: 0.6019\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4495 - accuracy: 0.8333 - val_loss: 0.7225 - val_accuracy: 0.6019\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4486 - accuracy: 0.8333 - val_loss: 0.7214 - val_accuracy: 0.6019\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4476 - accuracy: 0.8333 - val_loss: 0.7203 - val_accuracy: 0.6019\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4467 - accuracy: 0.8333 - val_loss: 0.7192 - val_accuracy: 0.6019\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4457 - accuracy: 0.8333 - val_loss: 0.7181 - val_accuracy: 0.6019\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4448 - accuracy: 0.8333 - val_loss: 0.7170 - val_accuracy: 0.6019\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4439 - accuracy: 0.8333 - val_loss: 0.7159 - val_accuracy: 0.6019\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4430 - accuracy: 0.8333 - val_loss: 0.7149 - val_accuracy: 0.6111\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4421 - accuracy: 0.8333 - val_loss: 0.7138 - val_accuracy: 0.6111\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4411 - accuracy: 0.8333 - val_loss: 0.7127 - val_accuracy: 0.6111\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4402 - accuracy: 0.8333 - val_loss: 0.7117 - val_accuracy: 0.6111\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.8333 - val_loss: 0.7106 - val_accuracy: 0.6111\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4384 - accuracy: 0.8333 - val_loss: 0.7095 - val_accuracy: 0.6111\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4375 - accuracy: 0.8333 - val_loss: 0.7085 - val_accuracy: 0.6111\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4367 - accuracy: 0.8333 - val_loss: 0.7075 - val_accuracy: 0.6111\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.8333 - val_loss: 0.7064 - val_accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4349 - accuracy: 0.8333 - val_loss: 0.7054 - val_accuracy: 0.6111\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4340 - accuracy: 0.8333 - val_loss: 0.7044 - val_accuracy: 0.6111\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4331 - accuracy: 0.8333 - val_loss: 0.7033 - val_accuracy: 0.6111\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4322 - accuracy: 0.8333 - val_loss: 0.7023 - val_accuracy: 0.6111\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 0.8333 - val_loss: 0.7013 - val_accuracy: 0.6111\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4305 - accuracy: 0.8333 - val_loss: 0.7002 - val_accuracy: 0.6111\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4296 - accuracy: 0.8333 - val_loss: 0.6992 - val_accuracy: 0.6111\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4288 - accuracy: 0.8333 - val_loss: 0.6982 - val_accuracy: 0.6111\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4279 - accuracy: 0.8333 - val_loss: 0.6972 - val_accuracy: 0.6111\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4271 - accuracy: 0.8333 - val_loss: 0.6962 - val_accuracy: 0.6111\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4262 - accuracy: 0.8333 - val_loss: 0.6952 - val_accuracy: 0.6111\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4254 - accuracy: 0.8333 - val_loss: 0.6942 - val_accuracy: 0.6111\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4245 - accuracy: 0.8333 - val_loss: 0.6932 - val_accuracy: 0.6111\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4237 - accuracy: 0.8333 - val_loss: 0.6922 - val_accuracy: 0.6111\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4228 - accuracy: 0.8333 - val_loss: 0.6912 - val_accuracy: 0.6111\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4220 - accuracy: 0.8333 - val_loss: 0.6903 - val_accuracy: 0.6111\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4212 - accuracy: 0.8333 - val_loss: 0.6893 - val_accuracy: 0.6111\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4203 - accuracy: 0.8333 - val_loss: 0.6883 - val_accuracy: 0.6111\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4195 - accuracy: 0.8333 - val_loss: 0.6873 - val_accuracy: 0.6111\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4187 - accuracy: 0.8333 - val_loss: 0.6864 - val_accuracy: 0.6111\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.8333 - val_loss: 0.6854 - val_accuracy: 0.6111\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4171 - accuracy: 0.8333 - val_loss: 0.6845 - val_accuracy: 0.6111\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4163 - accuracy: 0.8333 - val_loss: 0.6835 - val_accuracy: 0.6111\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4155 - accuracy: 0.8333 - val_loss: 0.6825 - val_accuracy: 0.6111\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4147 - accuracy: 0.8333 - val_loss: 0.6816 - val_accuracy: 0.6111\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8333 - val_loss: 0.6807 - val_accuracy: 0.6111\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4131 - accuracy: 0.8333 - val_loss: 0.6797 - val_accuracy: 0.6204\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4123 - accuracy: 0.8333 - val_loss: 0.6788 - val_accuracy: 0.6296\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4115 - accuracy: 0.8333 - val_loss: 0.6778 - val_accuracy: 0.6296\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4107 - accuracy: 0.8333 - val_loss: 0.6769 - val_accuracy: 0.6296\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4099 - accuracy: 0.8333 - val_loss: 0.6760 - val_accuracy: 0.6296\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4091 - accuracy: 0.8333 - val_loss: 0.6750 - val_accuracy: 0.6296\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4084 - accuracy: 0.8333 - val_loss: 0.6741 - val_accuracy: 0.6296\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4076 - accuracy: 0.8333 - val_loss: 0.6732 - val_accuracy: 0.6296\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4068 - accuracy: 0.8333 - val_loss: 0.6723 - val_accuracy: 0.6296\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4061 - accuracy: 0.8333 - val_loss: 0.6714 - val_accuracy: 0.6296\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4053 - accuracy: 0.8333 - val_loss: 0.6705 - val_accuracy: 0.6296\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4045 - accuracy: 0.8333 - val_loss: 0.6695 - val_accuracy: 0.6296\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4038 - accuracy: 0.8333 - val_loss: 0.6686 - val_accuracy: 0.6296\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4030 - accuracy: 0.8333 - val_loss: 0.6677 - val_accuracy: 0.6296\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4023 - accuracy: 0.8333 - val_loss: 0.6668 - val_accuracy: 0.6296\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4015 - accuracy: 0.8333 - val_loss: 0.6659 - val_accuracy: 0.6296\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4008 - accuracy: 0.8333 - val_loss: 0.6650 - val_accuracy: 0.6296\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4001 - accuracy: 0.8333 - val_loss: 0.6641 - val_accuracy: 0.6296\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3993 - accuracy: 0.8333 - val_loss: 0.6632 - val_accuracy: 0.6296\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3986 - accuracy: 0.8333 - val_loss: 0.6622 - val_accuracy: 0.6296\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3979 - accuracy: 0.8333 - val_loss: 0.6613 - val_accuracy: 0.6296\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.6604 - val_accuracy: 0.6296\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3964 - accuracy: 0.8333 - val_loss: 0.6595 - val_accuracy: 0.6296\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3957 - accuracy: 0.8333 - val_loss: 0.6586 - val_accuracy: 0.6296\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3950 - accuracy: 0.8333 - val_loss: 0.6577 - val_accuracy: 0.6296\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3942 - accuracy: 0.8333 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3935 - accuracy: 0.8333 - val_loss: 0.6559 - val_accuracy: 0.6296\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3928 - accuracy: 0.8333 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3921 - accuracy: 0.8333 - val_loss: 0.6541 - val_accuracy: 0.6296\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3914 - accuracy: 0.8333 - val_loss: 0.6532 - val_accuracy: 0.6296\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3907 - accuracy: 0.8333 - val_loss: 0.6524 - val_accuracy: 0.6296\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.6515 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3893 - accuracy: 0.8333 - val_loss: 0.6506 - val_accuracy: 0.6296\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3886 - accuracy: 0.9167 - val_loss: 0.6497 - val_accuracy: 0.6296\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3879 - accuracy: 0.9167 - val_loss: 0.6488 - val_accuracy: 0.6296\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3872 - accuracy: 0.9167 - val_loss: 0.6480 - val_accuracy: 0.6296\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3865 - accuracy: 0.9167 - val_loss: 0.6471 - val_accuracy: 0.6296\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3858 - accuracy: 0.9167 - val_loss: 0.6462 - val_accuracy: 0.6296\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3851 - accuracy: 0.9167 - val_loss: 0.6454 - val_accuracy: 0.6389\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3844 - accuracy: 0.9167 - val_loss: 0.6445 - val_accuracy: 0.6481\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3837 - accuracy: 0.9167 - val_loss: 0.6436 - val_accuracy: 0.6481\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3830 - accuracy: 0.9167 - val_loss: 0.6428 - val_accuracy: 0.6481\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3824 - accuracy: 0.9167 - val_loss: 0.6419 - val_accuracy: 0.6481\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3817 - accuracy: 0.9167 - val_loss: 0.6411 - val_accuracy: 0.6481\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3810 - accuracy: 0.9167 - val_loss: 0.6402 - val_accuracy: 0.6481\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3803 - accuracy: 0.9167 - val_loss: 0.6394 - val_accuracy: 0.6481\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3797 - accuracy: 0.9167 - val_loss: 0.6385 - val_accuracy: 0.6481\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3790 - accuracy: 0.9167 - val_loss: 0.6377 - val_accuracy: 0.6481\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3783 - accuracy: 0.9167 - val_loss: 0.6368 - val_accuracy: 0.6481\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3777 - accuracy: 0.9167 - val_loss: 0.6360 - val_accuracy: 0.6574\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3770 - accuracy: 0.9167 - val_loss: 0.6351 - val_accuracy: 0.6574\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3763 - accuracy: 0.9167 - val_loss: 0.6343 - val_accuracy: 0.6574\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3757 - accuracy: 0.9167 - val_loss: 0.6335 - val_accuracy: 0.6574\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3750 - accuracy: 0.9167 - val_loss: 0.6326 - val_accuracy: 0.6574\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3744 - accuracy: 0.9167 - val_loss: 0.6318 - val_accuracy: 0.6574\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3737 - accuracy: 0.9167 - val_loss: 0.6310 - val_accuracy: 0.6574\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3731 - accuracy: 0.9167 - val_loss: 0.6301 - val_accuracy: 0.6481\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3724 - accuracy: 0.9167 - val_loss: 0.6293 - val_accuracy: 0.6481\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3718 - accuracy: 0.9167 - val_loss: 0.6285 - val_accuracy: 0.6481\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3711 - accuracy: 0.9167 - val_loss: 0.6277 - val_accuracy: 0.6481\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3705 - accuracy: 0.9167 - val_loss: 0.6268 - val_accuracy: 0.6481\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3699 - accuracy: 0.9167 - val_loss: 0.6260 - val_accuracy: 0.6481\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3692 - accuracy: 0.9167 - val_loss: 0.6252 - val_accuracy: 0.6481\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3686 - accuracy: 0.9167 - val_loss: 0.6244 - val_accuracy: 0.6481\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3680 - accuracy: 0.9167 - val_loss: 0.6236 - val_accuracy: 0.6481\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3673 - accuracy: 0.9167 - val_loss: 0.6228 - val_accuracy: 0.6481\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3667 - accuracy: 0.9167 - val_loss: 0.6220 - val_accuracy: 0.6481\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3661 - accuracy: 0.9167 - val_loss: 0.6212 - val_accuracy: 0.6481\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3655 - accuracy: 0.9167 - val_loss: 0.6204 - val_accuracy: 0.6481\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3648 - accuracy: 0.9167 - val_loss: 0.6196 - val_accuracy: 0.6481\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3642 - accuracy: 0.9167 - val_loss: 0.6188 - val_accuracy: 0.6481\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3636 - accuracy: 0.9167 - val_loss: 0.6180 - val_accuracy: 0.6481\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3630 - accuracy: 0.9167 - val_loss: 0.6172 - val_accuracy: 0.6481\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3624 - accuracy: 0.9167 - val_loss: 0.6164 - val_accuracy: 0.6481\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3618 - accuracy: 0.9167 - val_loss: 0.6156 - val_accuracy: 0.6481\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3612 - accuracy: 0.9167 - val_loss: 0.6149 - val_accuracy: 0.6481\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3606 - accuracy: 0.9167 - val_loss: 0.6141 - val_accuracy: 0.6481\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3599 - accuracy: 0.9167 - val_loss: 0.6133 - val_accuracy: 0.6481\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3593 - accuracy: 0.9167 - val_loss: 0.6125 - val_accuracy: 0.6481\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3587 - accuracy: 0.9167 - val_loss: 0.6117 - val_accuracy: 0.6481\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 0.9167 - val_loss: 0.6109 - val_accuracy: 0.6481\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3575 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.6481\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3569 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.6481\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3563 - accuracy: 1.0000 - val_loss: 0.6086 - val_accuracy: 0.6481\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3557 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.6481\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3552 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.6481\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.6481\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3540 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.6481\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3534 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.6481\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3528 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3522 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.6481\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3516 - accuracy: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.6481\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3510 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.6481\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3505 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.6481\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3499 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.6481\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.6481\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3487 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.6481\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3482 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.6574\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3476 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.6574\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3470 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.6574\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3465 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.6574\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3459 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.6574\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3454 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.6574\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3448 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.6574\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3442 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.6574\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3437 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.6574\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3431 - accuracy: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.6574\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3426 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.6574\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3420 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.6574\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3415 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.6574\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3409 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.6574\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3404 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.6574\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3398 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.6574\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3393 - accuracy: 1.0000 - val_loss: 0.5862 - val_accuracy: 0.6574\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3387 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.6574\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3382 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.6574\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3377 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.6574\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3371 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.6574\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3366 - accuracy: 1.0000 - val_loss: 0.5826 - val_accuracy: 0.6574\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3360 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.6667\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3355 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.6667\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3350 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.6667\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3344 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.6667\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3339 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.6667\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3334 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.6667\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3328 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.6667\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3323 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.6667\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3318 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.6667\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3313 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.6667\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3307 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.6759\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3302 - accuracy: 1.0000 - val_loss: 0.5741 - val_accuracy: 0.6759\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3297 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.6759\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3292 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.6759\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3286 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.6759\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3281 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.6759\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3276 - accuracy: 1.0000 - val_loss: 0.5707 - val_accuracy: 0.6759\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3271 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.6759\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3266 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.6759\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.6759\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3255 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.6759\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3250 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.6759\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3245 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.6759\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3240 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.6759\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3235 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.6759\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3230 - accuracy: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.6759\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3225 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.6759\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3220 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.6852\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3215 - accuracy: 1.0000 - val_loss: 0.5625 - val_accuracy: 0.6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3209 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.6852\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3204 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.6852\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3199 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.6852\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.6852\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3189 - accuracy: 1.0000 - val_loss: 0.5591 - val_accuracy: 0.6852\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3184 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.6852\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3179 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.6852\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.6852\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3169 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.6852\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3164 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.6852\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3159 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.6944\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3154 - accuracy: 1.0000 - val_loss: 0.5544 - val_accuracy: 0.6944\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3149 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.7037\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3144 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.7037\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3139 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.7037\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3135 - accuracy: 1.0000 - val_loss: 0.5518 - val_accuracy: 0.7037\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3130 - accuracy: 1.0000 - val_loss: 0.5511 - val_accuracy: 0.7037\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.7037\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3120 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.7037\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.7037\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3110 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.7037\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3105 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.7037\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3100 - accuracy: 1.0000 - val_loss: 0.5472 - val_accuracy: 0.7037\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3095 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.7037\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.7037\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3085 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.7037\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3081 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.7037\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.7037\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.7037\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.7037\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3061 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.7037\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.7037\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3052 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.7037\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3047 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.7037\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3042 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.7037\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3037 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.7037\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3032 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.7037\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3028 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.7037\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3023 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.7037\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3018 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.7037\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3013 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.7037\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3009 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 0.7037\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3004 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.7037\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2999 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.7037\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2995 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.7037\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2990 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.7037\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2985 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.7037\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2980 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.7037\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2976 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.7037\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2971 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.7037\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2966 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.7130\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2962 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.7130\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2957 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.7130\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2952 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.7222\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2948 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.7222\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2943 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.7222\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2939 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.7222\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2934 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.7222\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2925 - accuracy: 1.0000 - val_loss: 0.5238 - val_accuracy: 0.7222\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.7222\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2915 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.7222\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2911 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.7222\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.7222\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2902 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.7315\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.7315\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2893 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.7315\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2888 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.7315\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2884 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.7315\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2879 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.7315\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2874 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.7315\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2870 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.7315\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.7315\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2861 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.7315\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2856 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.7315\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2852 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.7315\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2847 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.7315\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2843 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.7315\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.7315\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2834 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.7315\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.7315\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2825 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.7315\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2821 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.7315\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.7315\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2812 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.7315\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2807 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.7315\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.7407\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7407\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2794 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.7407\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.7407\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2785 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.7407\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2777 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.7593\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2772 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.7593\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.7593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=500, #batch_size=256,\n",
    "                    validation_data = (x_valid, y_valid)\n",
    "                    # validation_split=0.2 # Optionally use a split here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# alternatively could have specified a specific batch to train on\n",
    "# model.train_on_batch(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [[ 0.1569561   0.394767    0.26069272  0.11085547  0.10841848  0.12357521\n",
      "   0.0226829   0.21533805 -0.41132662  0.3713899  -0.17221689 -0.1293218\n",
      "   0.19827442 -0.0658451  -0.19697206  0.39728948 -0.03390318 -0.06169968\n",
      "   0.08316299  0.06300118  0.19619006 -0.24035344  0.16560946  0.29391915\n",
      "  -0.4086256   0.02635567 -0.30773464  0.3377133  -0.16544005  0.04594629]\n",
      " [-0.27543253 -0.0424483   0.1784971  -0.06078897  0.3335699   0.35372943\n",
      "  -0.23511958  0.27432808 -0.21819036 -0.13631745 -0.01940249 -0.3268805\n",
      "   0.00104894  0.13038494 -0.22395216 -0.10945529  0.21690334 -0.42385748\n",
      "  -0.30270877  0.16502656  0.03356233 -0.02865732 -0.1494655   0.00313359\n",
      "   0.0391233  -0.17406304  0.02800589 -0.40967485  0.08730655 -0.19129376]\n",
      " [-0.3984517  -0.41125527  0.00536411 -0.36663988 -0.560606   -0.05737343\n",
      "   0.2137177  -0.11969163 -0.24469773  0.23064853  0.20154905 -0.04491046\n",
      "  -0.17684954 -0.2867819   0.3169668  -0.0692732  -0.24965835 -0.11984838\n",
      "   0.08783693 -0.0449794  -0.4911057  -0.50850564 -0.33102253  0.07520837\n",
      "  -0.41035607 -0.30002892 -0.30805713  0.28194135  0.11679284  0.16179758]\n",
      " [-0.33811006  0.2591887  -0.22663566  0.06515789 -0.16059852 -0.25927824\n",
      "   0.08458026 -0.28639373 -0.15345335 -0.210539   -0.1406965  -0.07662778\n",
      "   0.02825779  0.20642811  0.44210237  0.02656687  0.13018662  0.68058765\n",
      "  -0.09615887 -0.0457928  -0.30129895 -0.43225622 -0.1924082  -0.30846223\n",
      "  -0.15613258 -0.04174201 -0.32563743 -0.03029725 -0.10262787  0.47765157]]\n",
      "\n",
      "Biases:\n",
      " [-0.06766233 -0.0209394  -0.05225259 -0.00933995  0.11339771 -0.00030058\n",
      " -0.03088702 -0.0013612  -0.00154616  0.24138655 -0.08564883  0.23903106\n",
      " -0.117594   -0.0497725   0.13617171  0.12887518  0.01574685  0.18100217\n",
      "  0.13640028  0.05956088  0.04650948  0.14065056 -0.00979292 -0.10407222\n",
      "  0.13340083 -0.03959272 -0.01670111  0.03909343 -0.03325907 -0.02494816]\n"
     ]
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print('Weights:\\n', weights)\n",
    "print()\n",
    "print('Biases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluating the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.492153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.454496</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.487615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.450737</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.481216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446002</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.473163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.440419</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.463690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.434093</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.492153       0.0  1.454496      0.055556\n",
       "1  1.487615       0.0  1.450737      0.055556\n",
       "2  1.481216       0.0  1.446002      0.055556\n",
       "3  1.473163       0.0  1.440419      0.055556\n",
       "4  1.463690       0.0  1.434093      0.055556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "columns = ['accuracy', 'val_accuracy']\n",
    "\n",
    "df[columns].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "columns = ['loss', 'val_loss']\n",
    "\n",
    "df[columns].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can look at the overall loss from our test data after training the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3710 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37096744775772095, 0.8666666746139526]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Could also just use a batch to evaluate\n",
    "# loss_and_metrics = model.evaluate(x_test, y_test, batch_size=16)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test)\n",
    "\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can have predictions (probability the data point is a particular class based on our trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9829584 , 0.00995784, 0.0070838 ],\n",
       "       [0.9787654 , 0.01269278, 0.00854177],\n",
       "       [0.0388788 , 0.47517148, 0.48594972],\n",
       "       [0.97985864, 0.01161486, 0.00852659],\n",
       "       [0.9733291 , 0.01476868, 0.01190224],\n",
       "       [0.06264996, 0.61917794, 0.31817213],\n",
       "       [0.9683801 , 0.01846033, 0.0131596 ],\n",
       "       [0.02967469, 0.5952555 , 0.3750699 ],\n",
       "       [0.04168391, 0.45701078, 0.50130534],\n",
       "       [0.972605  , 0.01686144, 0.01053361],\n",
       "       [0.9817385 , 0.00841553, 0.00984592],\n",
       "       [0.9855569 , 0.00869527, 0.00574784],\n",
       "       [0.9826956 , 0.00938403, 0.00792043],\n",
       "       [0.97348344, 0.01352104, 0.01299554],\n",
       "       [0.22265701, 0.48051456, 0.29682845],\n",
       "       [0.07922739, 0.6160129 , 0.30475974],\n",
       "       [0.957318  , 0.02862026, 0.01406182],\n",
       "       [0.15423511, 0.57953185, 0.26623312],\n",
       "       [0.05581926, 0.36883005, 0.57535076],\n",
       "       [0.12502585, 0.6050461 , 0.26992813],\n",
       "       [0.08140545, 0.55926716, 0.3593274 ],\n",
       "       [0.11328521, 0.63687426, 0.24984048],\n",
       "       [0.06735023, 0.38117737, 0.5514724 ],\n",
       "       [0.12817833, 0.6058196 , 0.2660021 ],\n",
       "       [0.05150376, 0.68386036, 0.26463583],\n",
       "       [0.9775753 , 0.01298984, 0.00943484],\n",
       "       [0.9834352 , 0.00951899, 0.00704581],\n",
       "       [0.0918325 , 0.49335524, 0.4148123 ],\n",
       "       [0.9700247 , 0.01615819, 0.01381708],\n",
       "       [0.07275528, 0.57647246, 0.35077226]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = model.predict(x_test)\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We want to say what is the predicted class, so we pick just the largest probability for each result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1,\n",
       "       2, 1, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(classes, axis=1)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, we can see how accurate our model was by seeing if the predicted classes match the actual labels. Note that this is calculated differently from how the loss is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86666667])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions  == np.argmax(y_test, axis=1)) / predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Saving it for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c04c7f554cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2109\u001b[0m     \"\"\"\n\u001b[1;32m   2110\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2111\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2112\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    144\u001b[0m           \u001b[0;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m--> 146\u001b[0;31m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    147\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[1;32m    148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   metadata = dict(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0;31m# of `self.layers`). Note that `self._self_tracked_trackables` is managed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m       \u001b[0;31m# by the tracking infrastructure and should not be used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m       \u001b[0mlayer_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m     config = {\n\u001b[1;32m    478\u001b[0m         \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    506\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    507\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 508\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;31m# or that `get_config` has been overridden:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m       raise NotImplementedError('Layer %s has arguments in `__init__` and '\n\u001b[0m\u001b[1;32m    720\u001b[0m                                 \u001b[0;34m'therefore must override `get_config`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                                 self.__class__.__name__)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`."
     ]
    }
   ],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-599ae1a23ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    199\u001b[0m         if (h5py is not None and\n\u001b[1;32m    200\u001b[0m             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 201\u001b[0;31m           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[1;32m    202\u001b[0m                                                   compile)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review \n",
    "- function of a perceptron from inputs to outputs = `output = activation(dot(inputs, weights) + bias)`\n",
    "- Forward Propagation - transformations from each node propagate to the next layers nodes. \n",
    "- Back-propagation - Updating weights and bias based on residuals \n",
    "- What is an activation function? \n",
    "- What is an optimizer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
