{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Modeling \n",
    "\n",
    "1. Get your raw text into a pandas dataframe\n",
    "2. Tokenize the text - splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens. \n",
    "3. Clean the text - this includes removing stopwords, punctuation and stems or lemmatizing \n",
    "4. Vectorize the text - convert the text to numeric form \n",
    "5. Fit/train an ML and/or deep learning model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:43.777741Z",
     "start_time": "2021-03-10T22:40:37.579130Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import re #regular expressions for pattern searching \n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/superheroes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:43.791596Z",
     "start_time": "2021-03-10T22:40:43.779400Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:43.801768Z",
     "start_time": "2021-03-10T22:40:43.793486Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['name', 'history_text', 'creator', 'alignment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:43.845052Z",
     "start_time": "2021-03-10T22:40:43.803481Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:43.851761Z",
     "start_time": "2021-03-10T22:40:43.846937Z"
    }
   },
   "outputs": [],
   "source": [
    "df.alignment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to clean our text \n",
    "\n",
    "1. Remove punctuation\n",
    "2. Tokenization\n",
    "3. Remove stopwords\n",
    "4. Lemmatize/Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:43.859979Z",
     "start_time": "2021-03-10T22:40:43.853763Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.190728Z",
     "start_time": "2021-03-10T22:40:43.861925Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_history(history):\n",
    "    history = \"\".join([word for word in history if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', history)\n",
    "    history = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return history\n",
    "\n",
    "df['history_clean'] = df['history_text'].apply(lambda x: clean_history(x.lower()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.205221Z",
     "start_time": "2021-03-10T22:40:48.194939Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.220044Z",
     "start_time": "2021-03-10T22:40:48.207589Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = df.loc[df['alignment'] == 'Good']\n",
    "df_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.232697Z",
     "start_time": "2021-03-10T22:40:48.221650Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bad = df.loc[df['alignment'] == 'Bad']\n",
    "df_bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.245198Z",
     "start_time": "2021-03-10T22:40:48.234321Z"
    }
   },
   "outputs": [],
   "source": [
    "df_neutral = df.loc[df['alignment'] == 'Neutral']\n",
    "df_neutral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.319029Z",
     "start_time": "2021-03-10T22:40:48.246543Z"
    }
   },
   "outputs": [],
   "source": [
    "#most frequent and least frequent words \n",
    "good_list = []  # list containing all words of all texts\n",
    "for x in df_good['history_clean']:  # loop over lists in df\n",
    "    good_list += x  # append elements of lists to full list\n",
    "\n",
    "good_val_counts = pd.Series(good_list).value_counts()  # make temporary Series to count\n",
    "good_val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.355505Z",
     "start_time": "2021-03-10T22:40:48.321185Z"
    }
   },
   "outputs": [],
   "source": [
    "#most frequent and least frequent words \n",
    "bad_list = []  # list containing all words of all texts\n",
    "for x in df_bad['history_clean']:  # loop over lists in df\n",
    "    bad_list += x  # append elements of lists to full list\n",
    "\n",
    "bad_val_counts = pd.Series(bad_list).value_counts()  # make temporary Series to count\n",
    "bad_val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.378939Z",
     "start_time": "2021-03-10T22:40:48.356769Z"
    }
   },
   "outputs": [],
   "source": [
    "#most frequent and least frequent words \n",
    "neutral_list = []  # list containing all words of all texts\n",
    "for x in df_neutral['history_clean']:  # loop over lists in df\n",
    "    neutral_list += x  # append elements of lists to full list\n",
    "\n",
    "neutral_val_counts = pd.Series(neutral_list).value_counts()  # make temporary Series to count\n",
    "neutral_val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.495644Z",
     "start_time": "2021-03-10T22:40:48.380408Z"
    }
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word\n",
    "from wordcloud import WordCloud\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.761866Z",
     "start_time": "2021-03-10T22:40:48.497214Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_words=100, width=400, height=200).generate(str(good_val_counts))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:48.983947Z",
     "start_time": "2021-03-10T22:40:48.763231Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_words=100, width=400, height=200).generate(str(bad_val_counts))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:49.224728Z",
     "start_time": "2021-03-10T22:40:48.985763Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_words=100, width=400, height=200).generate(str(neutral_val_counts))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:49.548079Z",
     "start_time": "2021-03-10T22:40:49.226886Z"
    }
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(str(df_good['history_clean']))\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df = pos_df.pos.value_counts()[:20]\n",
    "pos_df.plot(kind='bar', title=\"Parts of Speech in Good Histories\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:49.777085Z",
     "start_time": "2021-03-10T22:40:49.549994Z"
    }
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(str(df_bad['history_clean']))\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df = pos_df.pos.value_counts()[:20]\n",
    "pos_df.plot(kind='bar', title=\"Parts of Speech in Bad Histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:50.021328Z",
     "start_time": "2021-03-10T22:40:49.778754Z"
    }
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(str(df_neutral['history_clean']))\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df = pos_df.pos.value_counts()[:20]\n",
    "pos_df.plot(kind='bar', title=\"Parts of Speech in Neutral Histories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:50.433039Z",
     "start_time": "2021-03-10T22:40:50.023415Z"
    }
   },
   "outputs": [],
   "source": [
    "(pd.Series(nltk.ngrams(good_list, 2)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:50.580133Z",
     "start_time": "2021-03-10T22:40:50.439807Z"
    }
   },
   "outputs": [],
   "source": [
    "(pd.Series(nltk.ngrams(bad_list, 2)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:50.621999Z",
     "start_time": "2021-03-10T22:40:50.583309Z"
    }
   },
   "outputs": [],
   "source": [
    "(pd.Series(nltk.ngrams(neutral_list, 2)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing History Text: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:54.084689Z",
     "start_time": "2021-03-10T22:40:50.623504Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_history, ngram_range =(2, 2))\n",
    "X_tfidf = tfidf_vect.fit_transform(df['history_text'])\n",
    "print(X_tfidf.shape)\n",
    "print(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizers output sparse matrices\n",
    "\n",
    "_**Sparse Matrix**: A matrix in which most entries are 0. In the interest of efficient storage, a sparse matrix will be stored by only storing the locations of the non-zero elements._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:54.243763Z",
     "start_time": "2021-03-10T22:40:54.086033Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_df.columns = tfidf_vect.get_feature_names()\n",
    "X_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:54.297359Z",
     "start_time": "2021-03-10T22:40:54.245726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting top ranking features \n",
    "sums = X_tfidf.sum(axis = 0) \n",
    "data1 = [] \n",
    "for col, term in enumerate(X_tfidf_df.columns): \n",
    "    data1.append( (term, sums[0, col] )) \n",
    "ranking = pd.DataFrame(data1, columns = ['term', 'rank']) \n",
    "words = (ranking.sort_values('rank', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", words.head(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:40:54.314080Z",
     "start_time": "2021-03-10T22:40:54.298885Z"
    }
   },
   "outputs": [],
   "source": [
    "df['history_len'] = df['history_text'].apply(lambda x: len(x) - x.count(\" \")) #subtracting whitespace\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:42:33.272188Z",
     "start_time": "2021-03-10T22:42:32.792483Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 5000, 100)\n",
    "plt.hist(df[df['alignment'] == 'Good']['history_len'], bins, alpha=0.5, label='Good')\n",
    "plt.hist(df[df['alignment'] == 'Bad']['history_len'], bins, alpha=0.5, label='Bad')\n",
    "plt.hist(df[df['alignment'] == 'Neutral']['history_len'], bins, alpha=0.5, label='Neutral')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:42:37.117631Z",
     "start_time": "2021-03-10T22:42:36.805503Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3) * 100\n",
    "\n",
    "df['percent_punct'] = df['history_text'].apply(lambda x: count_punct(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:43:12.247181Z",
     "start_time": "2021-03-10T22:43:11.907229Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 10, 60)\n",
    "plt.hist(df[df['alignment'] == 'Good']['percent_punct'], bins, alpha=0.5, label='Good')\n",
    "plt.hist(df[df['alignment'] == 'Bad']['percent_punct'], bins, alpha=0.5, label='Bad')\n",
    "plt.hist(df[df['alignment'] == 'Neutral']['percent_punct'], bins, alpha=0.5, label='Neutral')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:43:15.401543Z",
     "start_time": "2021-03-10T22:43:15.236169Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 4000, 50)\n",
    "\n",
    "plt.hist(df['history_len'], bins)\n",
    "plt.title(\"History Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:43:31.770260Z",
     "start_time": "2021-03-10T22:43:31.499337Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 10, 50)\n",
    "\n",
    "plt.hist(df['percent_punct'], bins)\n",
    "plt.title(\"History Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:43:47.542342Z",
     "start_time": "2021-03-10T22:43:46.781339Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4, 5]:\n",
    "    plt.hist((df['history_len'])**(1/i), bins=50)\n",
    "    plt.title(\"Transformation: 1/{}\".format(str(i)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:14.056980Z",
     "start_time": "2021-03-10T22:45:14.054000Z"
    }
   },
   "outputs": [],
   "source": [
    "df['history_len'] = round(df['history_len']**(1/i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:14.846168Z",
     "start_time": "2021-03-10T22:45:14.842923Z"
    }
   },
   "outputs": [],
   "source": [
    "new_features_df = df[['history_len', 'percent_punct', 'alignment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:15.547299Z",
     "start_time": "2021-03-10T22:45:15.545018Z"
    }
   },
   "outputs": [],
   "source": [
    "alignment_dict = {'Good': 0, 'Bad': 1, 'Neutral': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:16.210427Z",
     "start_time": "2021-03-10T22:45:16.102361Z"
    }
   },
   "outputs": [],
   "source": [
    "new_features_df['alignment'] = [alignment_dict[item] for item in new_features_df.alignment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:19.623320Z",
     "start_time": "2021-03-10T22:45:19.620235Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tfidf_df.reset_index(drop=True, inplace=True)\n",
    "new_features_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:20.699007Z",
     "start_time": "2021-03-10T22:45:20.316145Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([new_features_df, X_tfidf_df], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:21.929712Z",
     "start_time": "2021-03-10T22:45:21.421241Z"
    }
   },
   "outputs": [],
   "source": [
    "X.drop(['alignment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:22.364960Z",
     "start_time": "2021-03-10T22:45:22.137622Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, new_features_df['alignment'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:22.790069Z",
     "start_time": "2021-03-10T22:45:22.575702Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=50, max_depth=20, n_jobs=-1)\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:23.154613Z",
     "start_time": "2021-03-10T22:45:22.989265Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:45:23.570939Z",
     "start_time": "2021-03-10T22:45:23.421021Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs \n",
    "\n",
    "#### TF-IDF\n",
    "\n",
    "![](https://image.slidesharecdn.com/9bc43139-1398-4c31-a9cf-ed08dd37ef13-150521205535-lva1-app6891/95/text-mining-association-rules-and-decision-tree-learning-26-638.jpg?cb=1432241853)\n",
    "\n",
    "#### Word-to-Vec\n",
    "- The skip gram \n",
    "![](https://media.geeksforgeeks.org/wp-content/uploads/word2vec_diagram-1.jpg)\n",
    "\n",
    "- Cosine Similarity\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/img_8.png)\n",
    "![](https://www.mathsisfun.com/algebra/images/cosine-graph.svg)\n",
    "\n",
    "#### Recurrent Neural Networks \n",
    "- A recurrent neural network (RNN) is a type of artificial neural network commonly used in speech recognition and natural language processing (NLP). RNNs are designed to recognize a data's sequential characteristics and use patterns to predict the next likely scenario.  RNN unlike feed forward neural networks(think CNNs) - can use their internal memory to process arbitrary sequences of inputs.\n",
    "[Turtorials Point - CNNs vs. RNNs](https://www.tutorialspoint.com/tensorflow/tensorflow_cnn_and_rnn_difference.htm)\n",
    "![](https://www.nexmo.com/wp-content/uploads/2020/10/Recurrent-neural-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T01:02:34.360700Z",
     "start_time": "2021-03-11T01:01:55.314223Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim \n",
    "import gensim.downloader as api \n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T01:02:37.455025Z",
     "start_time": "2021-03-11T01:02:37.451010Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_embeddings['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T01:05:33.425297Z",
     "start_time": "2021-03-11T01:05:33.406543Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_embeddings.most_similar('dinosaur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:54:36.258232Z",
     "start_time": "2021-03-10T22:54:35.925090Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:54:37.476293Z",
     "start_time": "2021-03-10T22:54:37.461725Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.wv('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:25.303197Z",
     "start_time": "2021-03-10T22:46:18.736686Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(new_features_df['alignment'])\n",
    "encoded_Y = encoder.transform(new_features_df['alignment'])\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:25.309223Z",
     "start_time": "2021-03-10T22:46:25.305151Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn_X_train, rnn_X_test, rnn_y_train, rnn_y_test = train_test_split(df['history_text'],\n",
    "                                                                    dummy_y,\n",
    "                                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:27.819417Z",
     "start_time": "2021-03-10T22:46:27.816931Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer #clean and tokenize the data \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will clean and tokenize our dataset. Also, it will build a vocabulary of all of the words in our training set and assign it an index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:30.230651Z",
     "start_time": "2021-03-10T22:46:29.793796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(rnn_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:34.195205Z",
     "start_time": "2021-03-10T22:46:33.773935Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(rnn_X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(rnn_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:34.420457Z",
     "start_time": "2021-03-10T22:46:34.413756Z"
    }
   },
   "outputs": [],
   "source": [
    "# What do these sequences look like? Each integer represents a word in the first text history, this is the 1st text history\n",
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:38.356412Z",
     "start_time": "2021-03-10T22:46:38.342490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pad the sequences so each sequence is the same length\n",
    "\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, 50) \n",
    "X_test_seq_padded = pad_sequences(X_test_seq, 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:39.238246Z",
     "start_time": "2021-03-10T22:46:39.234226Z"
    }
   },
   "outputs": [],
   "source": [
    "# What do these padded sequences look like?\n",
    "X_train_seq_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:40.672809Z",
     "start_time": "2021-03-10T22:46:40.665126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the tools needed from keras and define functions to calculate recall and precision\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:48.401272Z",
     "start_time": "2021-03-10T22:46:48.224635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct a simple RNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
    "model.add(LSTM(32, dropout=.2, recurrent_dropout=0))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:49.610918Z",
     "start_time": "2021-03-10T22:46:49.530890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T22:46:59.291183Z",
     "start_time": "2021-03-10T22:46:51.172326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the RNN model\n",
    "history = model.fit(X_train_seq_padded, rnn_y_train, \n",
    "                    batch_size=32, epochs=10,\n",
    "                    validation_data=(X_test_seq_padded, rnn_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
