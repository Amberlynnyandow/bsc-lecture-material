{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "## Objectives \n",
    "1. Understand the differences between variance, covariance and correlation. \n",
    "2. Be able to explain each piece of the linear regression formula including terminology typically associated with regression \n",
    "3. Understand the assumptions of regression \n",
    "3. Use diabetes dataset to fit a simple linear regression model using _statsmodels package_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is linear regression? \n",
    "> Regression Analysis is a **parametric** technique meaning a set of parameters are used to **predict** the value of an unknown target variable (or dependent variable)  based on one or more of known input features (or independent variables, predictors), often denoted by _x_  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Correlation\n",
    "\n",
    "The idea of _correlation_ is the simple idea that variables often change _together_. For a simple example, cities with more buses tend to have higher populations.\n",
    "\n",
    "We might observe that, as one variable X increases, so does another Y, OR that as X increases, Y decreases.\n",
    "\n",
    "The _covariance_ describes how two variables co-vary. Note the similarity in the definition to the definition of ordinary variance:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance**: Measure of dispersion from the mean for continuous random variables. How far a set of numbers are spread out from their overall average value. <br/>\n",
    "n = # of data points <br/>\n",
    "$x_i$ = individuals data points <br/>\n",
    "$mu$ = mean \n",
    "$$\\sigma^2 = \\sum_{i}^{n}\\frac{(x_i -\\mu )^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covariance**: Measure of how variables differ/relate to one another\n",
    "$$\\sigma_{xy} = \\frac{\\sum_{i,j}^{n} (x_i -\\mu_x )(y_j - \\mu_y)}{n}$$\n",
    "\n",
    "Problem: \n",
    "* Positive covariance  --> correlates (together)\n",
    "* Negative covariance --> correlates inversely\n",
    "\n",
    "But ranges (-∞,∞) so what is a \"stronger\" relationship?\n",
    "\n",
    "So, we need: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "Pearson's Correlation: Normalizes covariance so relationships are now represented on a [-1, 1] scale\n",
    "\n",
    "$$ r = \\frac{\\sum_{i,j}^{n}(x_i -\\mu_x)(y_j - \\mu_y)} {\\sqrt{\\sum_{i,j}^{n}(x_i - \\mu_x)^2 (y_j-\\mu_y)^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-0-10-03-cov-corr-online-ds-sp-000/master/images/correlation.png' width=70%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#load the dataset\n",
    "df = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "#Print the first 5 rows of the dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Note:* Examples in this lecture use the Pima Indians Diabetes data which was taken from a larger collection of data, originally collected by the National Institute of Diabetes and Digestive Kidney Diseases. It provides diagnostic data on 768 females of Pima Indian heritage aged 21 years or older. The analyses presented in this post are intended to illustrate an approach to linear regression modeling and should not be used to draw substantive conclusions on biomedical pathologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, [\"Age\", \"Glucose\"]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Age column provides each participant's age measured in years. Glucose is a measure of each participant's plasma glucose concentration at 2 hours from an oral glucose tolerance test. In the current analyses we will use age to predict participants' plasma glucose concentration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics: \n",
    "**Independent Variable:** the data we are using to make a prediction. In this case: _Age_. <br/>\n",
    "AKA - predictor, feature, inputs. \n",
    "\n",
    "**Dependent Variable:** the data we are trying to predict. In this case: _glucose_. <br/>\n",
    "AKA - target, outcome or outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first model:\n",
    "\n",
    "$$ y = m \\cdot x + b $$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $x$: input column (just one for now)\n",
    "- $y$: output column (column we're trying to predict)\n",
    "\n",
    "Solving for the coefficients $m$(our slope) and $b$(y-intercept)  - based on the line that 'best' represents the relationship between $x$ and $y$, _assuming_ that relationship is a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's pre-process our data and do a tiny bit of EDA - Remember our crisp-dm method?** \n",
    "![](https://www.datascience-pm.com/wp-content/uploads/2021/02/CRISP-DM.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many rows have 0 for Glucose? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's get rid of zeros using .loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great, now let's look at the correlation between our two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Age\", \"Glucose\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between age and glucose concentration is 0.27, indicating a slight positive relationship. This means that older participants tend to have higher glucose concentrations relative to younger participants, on average. We can visualize this relationship with a scatterplot to get a better idea of the observed relationship between age and glucose levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes()\n",
    "ax.scatter(df[\"Age\"], df[\"Glucose\"], color='r', alpha=0.20)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Glucose')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Age', y='Glucose', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Age']\n",
    "y = df['Glucose']\n",
    "\n",
    "plt.plot(X, y, 'o')\n",
    "m, b = np.polyfit(X, y, 1)\n",
    "\n",
    "plt.plot(X, m*X + b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a model using StatsModels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the intercept value from our model lends itself to an interpretation that is consistent with the observed data, it is a good idea to recode age by subtracting the minimum value of 21 from each individual age value. Otherwise, the intercept value will be extrapolated to observations at age zero, which doesn't exist in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"] = df[\"Age\"] - df[\"Age\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate OLS model \n",
    "model = sm.OLS(df['Glucose'], df['Age'])\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ <br/>\n",
    "sm.OLS only contains information on the structure of our model. If you run sm in a Python shell or Jupyter notebook cell, you will just get the following output:_<statsmodels.regression.linear_model.OLS at 0x1a27daa990>_ . At this point, we still need to fit the model to our data, which we can do by applying the fit method to sm.OLS. So, let's overwrite smOLS with a fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Interpretations of Summary stats\n",
    "There is a lot going on here, so I only want to focus on a few pieces of output. First, the R-squared has a value of 0.555. \n",
    "> First, if we interpret R² as the proportion of variance in the outcome accounted for by our model, this value tells us that our model — with just one independent variable — accounts for roughly 56% of the variance in glucose levels.\n",
    "\n",
    "> Second, the value of 5.4991 under the coef column in the Age row provides the regression weight for our predictor, age. We can interpret this value to mean the for every year increase in age the predicted glucose concentration increases by a value of roughly 5.50. Thus, a participant whose age is one year above the minimum (i.e., age 22) is expected to have a glucose concentration that is about 5.50 units higher than a participant who is at the minimum age (i.e., age 21)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How am I able to draw these conclusions? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's break down the regression line and the associated error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression_files/simple_regression.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **residual** is the difference between the actual value and the predicted value for a point we tried to predict where we knew the actual correct answer.\n",
    "\n",
    "\n",
    "$$ \\text{Squared Sum of Residuals} = \\sum\\limits_{i=1}^{n} (y_i - \\text{y_pred}_{i})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
