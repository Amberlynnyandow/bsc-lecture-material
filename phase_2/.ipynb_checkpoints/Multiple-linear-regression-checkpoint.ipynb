{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression \n",
    "The main idea here is pretty simple. Whereas, in simple linear regression we took our dependent variable to be a _function_ only of a single independent variable, here we'll be taking the dependent variable to be a _function_ of multiple independent variables.\n",
    "\n",
    "Our regression equation, then, instead of looking like $\\hat{y} = mx + b$, will now look like:\n",
    "\n",
    "$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + ... + \\hat{\\beta}_nx_n$.\n",
    "\n",
    "Remember that the hats ( $\\hat{}$ ) indicate parameters that are estimated.\n",
    "\n",
    "Is this still a best-fit *line*? Well, no. What does the graph of, say, z = x + y look like? [Here's](https://academo.org/demos/3d-surface-plotter/) a 3d-plotter. (Of course, once we get x's with subscripts beyond 2 it's going to be very hard to visualize. But in practice linear regressions can make use of dozens or even of hundreds of independent variables!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#read data into a DataFrame\n",
    "data = pd.read_csv('data/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the features/predictors?**\n",
    "\n",
    "*TV:* advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "\n",
    "*Radio:* advertising dollars spent on Radio\n",
    "\n",
    "*Newspaper:* advertising dollars spent on Newspaper\n",
    "\n",
    "**What is the target?**\n",
    "\n",
    "*Sales:* sales of a single product in a given market (in thousands of widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions About the Advertising Data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets this widget. The company might ask you the following: On the basis of this data, how should we spend our advertising money in the future?\n",
    "\n",
    "This general question might lead you to more specific questions:\n",
    "\n",
    "* Is there a relationship between ads and sales?\n",
    "* How strong is that relationship?\n",
    "* Which ad types contribute to sales?\n",
    "* What is the effect of each ad type of sales?\n",
    "* Given ad spending in a particular market, can sales be predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 200 observations, and thus 200 markets in the dataset.\n",
    "# Visualize the relationship between the features and the response using scatterplots\n",
    "fig, axs = plt.subplots(1, 3,)\n",
    "data.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter', x='Radio', y='Sales', ax=axs[1])\n",
    "data.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple regression with StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'Sales ~ TV'\n",
    "model = ols(formula=f, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it with SKLearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "#create X and y \n",
    "features = ['TV']\n",
    "X = data[features]\n",
    "y = data.Sales\n",
    "\n",
    "#instiatiate and fit \n",
    "slr = LinearRegression()\n",
    "slr.fit(X, y)\n",
    "\n",
    "#print coefficients \n",
    "print(slr.intercept_)\n",
    "print(slr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression \n",
    "We are still predicting a single variable(y) but now we are using multiple features(xs). This introduces several additional complexities but it also provides a great deal of additional flexibility and predictability.\n",
    "\n",
    "**Examples**: \n",
    "* Your Credit score \n",
    "* Price of a home \n",
    "\n",
    "\n",
    "**Modified formula**:\n",
    "$$ \\hat y = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2 x_2 +\\ldots + \\hat\\beta_n x_n $$ \n",
    "\n",
    "So, $n$ is the number of predictors, $\\beta_0$ is the intercept, and $\\hat y$ is the so-called \"fitted line\" or the predicted value associated with the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stasmodels\n",
    "f = 'Sales ~ TV + Radio + Newspaper'\n",
    "model = ols(formula=f, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Note_: R-squared vs. Adjusted R-squared \n",
    "To evaluate the overall fit of a linear model, we use the R-squared value\n",
    "\n",
    "R-squared is the proportion of variance explained\n",
    "It is the proportion of variance in the observed data that is explained by the model, or the reduction in error over the null model\n",
    "The null model just predicts the mean of the observed response, and thus it has an intercept and no slope\n",
    "R-squared is between 0 and 1\n",
    "Higher values are better because it means that more variance is explained by the model.\n",
    "\n",
    "The actual calculation of $R^2$ is:\n",
    "$\\Large R^2\\equiv 1-\\frac{\\Sigma_i(y_i - \\hat{y}_i)^2}{\\Sigma_i(y_i - \\bar{y})^2}$.\n",
    "\n",
    "$R^2$ is a measure of how much variation is in the dependent variable your model explains.\n",
    "\n",
    "Adjusted $R^2$\n",
    "There are some theoretical objections to using $R^2$ as an evaluator of a regression model.\n",
    "\n",
    "One objection is that, if we add another predictor to our model, $R^2$ can only increase! (It could hardly be that with more features I'd be able to account for less of the variation in the dependent variable than I could with the smaller set of features. We saw this with adding Newspaper ads.)\n",
    "\n",
    "One improvement is adjusted $R^2$:\n",
    "$\\Large R^2_{adj.}\\equiv 1 - \\frac{(1 - R^2)(n - 1)}{n - m - 1}$, where:\n",
    "\n",
    "n is the number of data points; and\n",
    "m is the number of predictors.\n",
    "This can be a better indicator of the quality of a regression model.\n",
    "\n",
    "R-squared will always increase as you add more features to the model, even if they are unrelated to the response\n",
    "Selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "* Adjusted R-squared\n",
    "Penalizes model complexity (to control for overfitting), but it generally under-penalizes complexity.\n",
    "\n",
    "**Better Solution**\n",
    "\n",
    "* Train/test split or cross-validation\n",
    "More reliable estimate.\n",
    "Better for choosing which of your models will best generalize to other data.\n",
    "There is extensive functionality for cross-validation in scikit-learn, including automated methods for searching different sets of parameters and different models.\n",
    "Cross-validation can be applied to any model, whereas the methods described above only apply to linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "\n",
    "features = ['TV', 'Radio', 'Newspaper']\n",
    "X = data[features]\n",
    "y = data.Sales\n",
    "\n",
    "mlr = LinearRegression() #instantiate \n",
    "mlr.fit(X, y) #fit \n",
    "\n",
    "print(mlr.coef_)\n",
    "print(mlr.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(features, mlr.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can use these coeffcients to determine how much money should be spent in a given market to sell a minimum number of widgets. With one additional caveat: \n",
    "\n",
    "**We must deal with multicollinearity.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Multicollinearity\n",
    "The interpretation of a regression coefficient is that it represents the average change in the dependent variable for each 1 unit change in a predictor, assuming that all the other predictor variables are kept constant. Multicollinearity occurs when 2 or more of the independent variables are higly correlated with each other.\n",
    "\n",
    "**How do we tell if variables are correlated with each other?**\n",
    "1. Look at a scatter matrix \n",
    "2. Look at a heatmap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scatter matrix returns scatterplots for relationships between two predictors, and histograms for a single feature on the diagonal.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data, figsize=(10,10));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The heatmap returns a matrix with the pearson correlation coeffcient given for each variable. Typically, we want to drop(or create an interaction) a variable that has a high(.7 or higher) correlation with another predictive feature but a lower correlation with the target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving onto Prediction\n",
    "* How can we tell if our predictions are accurate?\n",
    "* What is the bias/Variance tradeoff? \n",
    "* How can we improve our models performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation \n",
    "This is the process of controlling over-fitting so our model can generalize well when it receives new data. \n",
    "\n",
    "Our model is useless unless it generalizes well when we add new data. But how can we tell if our model is performing well? \n",
    "\n",
    "Your model is underfitting the training data when the model performs poorly on the testing data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y). Your model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples.\n",
    "\n",
    "![](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Trade-Off \n",
    "Review: \n",
    "\n",
    "> **Underfitting** happens when a model cannot learn the training data, nor can it generalize to new data.\n",
    "\n",
    "> **Overfitting** happens when a model learns the training data too well. In fact, so well that it is not generalizeable to new data\n",
    "\n",
    "Mathematically, if we look at the equation of MSE(mean of our sum of squared errors)\n",
    "$\\frac{1}{n}\\sum_{i=1}^{n}(y_{i} - \\hat y_{i})^2$\n",
    "\n",
    "We can apply bias and variance and it would like this: \n",
    "\n",
    "$ MSE = Bias(\\hat{f}(x))^2 + Var(\\hat{f}(x)) + \\sigma^2$\n",
    "\n",
    "Bias is usually associated with low model complexity, variance with high model complexity. \n",
    "\n",
    "![](https://files.ai-pool.com/a/eba93f5a75070f0fbb9d86bec8a009e9.png)\n",
    "\n",
    " <details>\n",
    "    <summary>So, what do you do if you have high bias or variance? </summary>\n",
    "    \n",
    "If we had high bias and low variance what should we do?<br/>\n",
    "- Get rid of outliers \n",
    "- Increase model complexity by adding polynomial features and/or interactions \n",
    "- Get more features(feature engineering) OR get more data\n",
    "\n",
    "If we had low bias and high variance what should we do? \n",
    "- decrease the complexity \n",
    "- reduce the size of your training set\n",
    "- reduce the amount of features \n",
    "- Get rid of outliers \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split \n",
    "We need to split our data into a training and a testing set, randomly. A 70/30 split is pretty standard but what you choose can depend on the model you are using.  \n",
    "\n",
    "**To evaluate our training and test sets, we will compare our $\\hat y$ with the actual value, $y$.**\n",
    " \n",
    "**Mean Squared Error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$\\frac{1}{n}\\sum_{i=1}^{n}(y_{i} - \\hat y_{i})^2$\n",
    " \n",
    "**Root Mean Squared Error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_{i} - \\hat y_{i})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split our data into training/testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate and fit \n",
    "mlr_split = LinearRegression()\n",
    "\n",
    "#fit\n",
    "mlr_split.fit(X_train, y_train)\n",
    "\n",
    "# calculate predictions on training and test sets\n",
    "y_hat_train = mlr_split.predict(X_train)\n",
    "y_hat_test = mlr_split.predict(X_test)\n",
    "\n",
    "#compare MSE for the predicted training and test values \n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squarred Error:', train_mse)\n",
    "print('Test Mean Squarred Error:', test_mse)\n",
    "\n",
    "print('Train score:', mlr_split.score(X_train, y_train))\n",
    "print('Test score:', mlr_split.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need k-fold Cross Validation \n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into k groups\n",
    "3. For each unique group:\n",
    "    * Take the group as a hold out or test data set\n",
    "    * Take the remaining groups as a training data set\n",
    "    * Fit a model on the training set and evaluate it on the test set\n",
    "    * Retain the evaluation score and discard the model\n",
    "4. Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*J2B_bcbd1-s1kpWOu_FZrg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = cross_val_score(mlr_split, X, y, cv=5)\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "# create a Series of booleans in which roughly half are True\n",
    "nums = np.random.rand(len(data))\n",
    "mask_large = nums > 0.5\n",
    "\n",
    "# initially set Size to small, then change roughly half to be large\n",
    "data['Size'] = 'small'\n",
    "\n",
    "# Series.loc is a purely label-location based indexer for selection by label\n",
    "data.loc[mask_large, 'Size'] = 'large'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables\n",
    "\n",
    "Up to now, all of our features have been numeric. What if one of our features was categorical?\n",
    "\n",
    "What is a categorical feature?\n",
    "**Examples**\n",
    "* gender\n",
    "* region/country\n",
    "* marital status \n",
    "* condition of an item <br/>\n",
    "[Review: ALL THE VARIABLES](https://www.statisticshowto.com/probability-and-statistics/types-of-variables/)\n",
    "\n",
    "### OneHotEncoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
